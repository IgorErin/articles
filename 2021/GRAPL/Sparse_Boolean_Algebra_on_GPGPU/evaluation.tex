\section{Evaluation}

% Evaluation of the proposed implemenation(s).

% What we need:
% - idea of the evaluation
% - what we want to show and measure
% - time performance, memory consumption, ops/per sec
% - what data we need?
% - very sparse, different distributions

We evaluate the applicability of the proposed backends for analysis of some real-world matrix data.
The experiments are designed as computational tasks, that arise as stand-alone or intermediate steps in the solving of practical problems. 
The purpose of the evaluation is to show the performance gain between the Boolean optimized and general-purpose operations. 
The comparison is not entirely fair, but the Boolean optimized libraries for GPU have not be introduced yet.

% Update CPU and RAM info
% Intel Core i7-6700 CPU @ 3.40GHz
% DDR4 64 GB RAM

% For evaluation, we used a PC with Ubuntu 20.04 installed.
% It has Intel core i7-4790 CPU, 3.6GHz, DDR4 32Gb RAM and GeForce GTX 1070 GPU with 8Gb VRAM.
For evaluation, we used a PC with Ubuntu 20.04 installed.
It has Intel Core i7-6700 CPU, 3.40Hz, DDR4 64Gb RAM and GeForce GTX 1070 GPU with 8Gb VRAM.
We measure only the execution time of the operations themselves.
The actual data is assumed to be loaded into the VRAM or RAM respectively in the appropriate format, required for the target tested framework.
Time to load data from the disc and prepare initial matrices state is excluded from the time measurements.

We use four sparse matrix libraries, CUSP, cuSPARSE, clSPARSE for GPU and SuiteSparse for CPU.
CUSP provides a template based implementation for operations, however it does not provide extra optimizations especially for boolean case values. Both cuSPARSE and clSPARSE provide operations only for types such as float or double.
However this limitation can be ignored, if we consider non-zero float values as \textit{true}.
SuiteSparse is a GraphBLAS API reference implementation for CPU with built-in boolean semiring.

For performance evaluations, we selected $10$ various square matrices, which are widely used for sparse matrices benchmarks, from the Sparse Matrix Collection at University of Florida~\cite{data:suitesparse_matrix_collection}.
Information about matrices is summarized in table~\ref{table:sparse_matrices}.
These matrices were selected because they correspond to (un)directed graphs 
and they are suitable for a correct application of multiplication and addition operations. 
For a detailed study, it is necessary to carry out measurements on specific algorithms and data. 

{\setlength{\tabcolsep}{0.3em}
\begin{table}
\centering
{
\caption{Sparse matrix data for evaluation.}
\label{table:sparse_matrices}
\scriptsize
\rowcolors{2}{black!2}{black!10}
\begin{tabular}{|c|l|r|r|r|r|}
\hline
\textnumero&Matrix $M$ & $\#$ Rows  & Nnz of $M$   & Nnz of $M^2$   & Nnz of $M + M^2$ \\
\hline
\hline
0&  wing             &    62,032    &   243,088    &    714,200     &    917,178       \\
1&  luxembourg\_osm  &   114,599    &   239,332    &    393,261     &    632,185       \\
2&  amazon0312       &   400,727    & 3,200,400    & 14,390,544     & 14,968,909       \\
3&  amazon-2008      &   735,323    & 5,158,388    & 25,366,745     & 26,402,678       \\
4&  web-Google       &   916,428    & 5,105,039    & 29,710,164     & 30,811,855       \\
5&  roadNet-PA       & 1,090,920    & 3,083,796    &  7,238,920     &  9,931,528       \\
6&  roadNet-TX       & 1,393,383    & 3,843,320    &  8,903,897     & 12,264,987       \\
7&  belgium\_osm     & 1,441,295    & 3,099,940    &  5,323,073     &  8,408,599       \\
8&  roadNet-CA       & 1,971,281    & 5,533,214    & 12,908,450     & 17,743,342       \\
9&  netherlands\_osm & 2,216,688    & 4,882,476    &  8,755,758     & 13,626,132       \\ 
\hline
\end{tabular}
}
\end{table}
}

The results of the evaluation are summarized in tables~\ref{table:eval_mm_results} and~\ref{table:eval_ma_results}.
Time is measured in milliseconds. 
Peak VRAM usage for GPU targets and peak RAM usage for SuiteSparse is measured in megabytes.
The result for each experiment is averaged over 10 runs.
The cell is left blank if the operation is not implemented in a library.

The first experiment is intended to measure the performance of the matrix-matrix multiplication as $M \times M$.
The results are presented in the table~\ref{table:eval_mm_results}.
We can see that cuBool and clBool show best performance among competitors.
CUSP, cuSPARSE and clSPARSE have good performance as well.
However, they have significant memory consumption,
which can negatively affect on processing of large data.

The second experiment is intended to measure performance of the element-wise matrix-matrix addition as $M + M^2$, where evaluation of the matrix $M^2$ is excluded from measurements.
The results are presented in the table~\ref{table:eval_ma_results}.
CUSP and cuSPARSE show nearly best performance among almost all runs.
cuBool and clBool show good performance as well. 
Memory consumption for cuBool is relatively small compared to other GPU libraries.
Thus, there is still space for clBool optimizations, so it requires a deep investigation in our future research.

% The numbers obtained in this experiment are more ambiguous than in the previous experiment.
% cuBool, CUSP and cuSPARSE show best performance among almost all runs.
% Memory consumption for cuBool is relatively small compared to CUSP and cuSPARSE. 
% clBool generally keeps its results within acceptable limits.
% However, it still lags behind SuiteSparse. 
% There is still space for optimizations, 
% so it requires a deep investigation in our future research.

% It is worth mentioning, that CUSP matrix-matrix addition implementation has significant memory consumption, which can negatively affect on processing of huge data.
% cuSPARSE performance can degrade in such case as well, since its implementation is based on hashing, which is very sensitive for out-of shared blocks memory access for large data processing.

{\setlength{\tabcolsep}{0.25em}
\begin{table}[t]
\centering
{
\caption{Matrix-matrix multiplication evaluation results\\(Time in milliseconds, Memory in megabytes).}
\label{table:eval_mm_results}
\scriptsize
\rowcolors{4}{black!2}{black!10}
\scalebox{0.915}{
\begin{tabular}{| c | r r | r r | r r | r r | r r | r r |}
\hline
$M$ & \multicolumn{2}{c|}{cuBool} & \multicolumn{2}{c|}{clBool} & \multicolumn{2}{c|}{CUSP} & \multicolumn{2}{c|}{cuSPRS} & \multicolumn{2}{c|}{clSPRS} & \multicolumn{2}{c|}{SuiteSprs} \\   
\textnumero& Time  & Mem & Time  & Mem  & Time   & Mem & Time  & Mem & Time  & Mem  & Time & Mem \\
\hline
\hline
0           & 1.9  & 93  & 1.9   & 89  & 5.2   & 125  & 20.1   & 155 & 4.2   & 105  & 7.9   & 22  \\ % 1.  wing             
1           & 2.4  & 91  & 2.0   & 89  & 3.7   & 111  & 1.7    & 151 & 6.9   & 97   & 3.1   & 169 \\ % 2.  luxembourg\_osm  
2           & 23.2 & 165 & 55.5  & 163 & 108.5 & 897  & 412.8  & 301 & 52.2  & 459  & 257.6 & 283 \\ % 3.  amazon0312       
3           & 33.3 & 225 & 82.1  & 221 & 172.0 & 1409 & 184.8  & 407 & 77.4  & 701  & 369.5 & 319 \\ % 4.  amazon-2008      
4           & 41.8 & 241 & 127.6 & 239 & 246.2 & 1717 & 4761.3 & 439 & 207.5 & 1085 & 673.3 & 318 \\ % 5.  web-Google       
5           & 18.1 & 157 & 14.2  & 153 & 42.1  & 481  & 37.5   & 247 & 56.6  & 283  & 66.6  & 294 \\ % 6.  roadNet-PA       
6           & 22.6 & 167 & 16.9  & 165 & 53.1  & 581  & 46.7   & 271 & 70.4  & 329  & 80.7  & 328 \\ % 7.  roadNet-TX       
7           & 23.2 & 151 & 16.9  & 159 & 32.9  & 397  & 26.7   & 235 & 68.2  & 259  & 56.9  & 302 \\ % 8.  belgium\_osm     
8           & 32.0 & 199 & 23.4  & 211 & 74.4  & 771  & 65.8   & 325 & 98.2  & 433  & 114.5 & 344 \\ % 9.  roadNet-CA       
9           & 35.3 & 191 & 24.9  & 189 & 51.0  & 585  & 51.4   & 291 & 102.8 & 361  & 90.9  & 311 \\ % 10. netherlands\_osm  
\hline
\end{tabular}
}
}
\end{table}
}

{\setlength{\tabcolsep}{0.25em}
\begin{table}[t]
\centering
{
\caption{Element-wise matrix-matrix addition evaluation results\\(Time in milliseconds, Memory in megabytes).}
\label{table:eval_ma_results}
\scriptsize
\rowcolors{4}{black!2}{black!10}
\scalebox{0.95}{
\begin{tabular}{| c | r r | r r| r r | r r | c c | r r |}
\hline
$M$ & \multicolumn{2}{c|}{cuBool} & \multicolumn{2}{c|}{clBool} & \multicolumn{2}{c|}{CUSP} & \multicolumn{2}{c|}{cuSPRS} & \multicolumn{2}{c|}{clSPRS} & \multicolumn{2}{c|}{SuiteSprs} \\   
\textnumero & Time & Mem & Time & Mem & Time & Mem & Time  & Mem & Time & Mem & Time & Mem\\
\hline
\hline
0           & 1.1  & 95  & 1.9   & 105 & 1.4  & 105 & 2.4  & 163 & -    & -   & 2.3  & 176 \\ % 1.  wing             
1           & 1.7  & 95  & 1.6   & 109 & 1.0  & 97  & 0.8  & 151 & -    & -   & 1.6  & 174 \\ % 2.  luxembourg\_osm  
2           & 11.4 & 221 & 23.8  & 543 & 16.2 & 455 & 24.3 & 405 & -    & -   & 37.2 & 297 \\ % 3.  amazon0312       
3           & 17.5 & 323 & 35.4  & 877 & 29.5 & 723 & 27.2 & 595 & -    & -   & 64.8 & 319 \\ % 4.  amazon-2008      
4           & 24.8 & 355 & 43.1  & 989 & 31.9 & 815 & 89.0 & 659 & -    & -   & 77.2 & 318 \\ % 5.  web-Google       
5           & 16.9 & 189 & 12.5  & 359 & 11.2 & 329 & 11.6 & 317 & -    & -   & 36.6 & 287 \\ % 6.  roadNet-PA       
6           & 19.6 & 209 & 15.4  & 429 & 14.5 & 385 & 16.9 & 357 & -    & -   & 45.3 & 319 \\ % 7.  roadNet-TX       
7           & 19.5 & 179 & 10.5  & 321 & 10.2 & 303 & 10.5 & 297 & -    & -   & 28.5 & 302 \\ % 8.  belgium\_osm     
8           & 30.5 & 259 & 22.4  & 579 & 19.4 & 513 & 20.2 & 447 & -    & -   & 65.2 & 331 \\ % 9.  roadNet-CA       
9           & 30.1 & 233 & 18.6  & 457 & 14.8 & 423 & 18.3 & 385 & -    & -   & 50.2 & 311 \\ % 10. netherlands\_osm  
\hline
\end{tabular}
}
}
\end{table}
}
@article{valiant1975general,
	title={General context-free recognition in less than cubic time},
	author={Valiant, Leslie G},
	journal={Journal of computer and system sciences},
	volume={10},
	number={2},
	pages={308--315},
	year={1975},
	publisher={Academic Press}
}


@article{10.1145/505241.505242,
	author = {Lee, Lillian},
	title = {Fast Context-Free Grammar Parsing Requires Fast Boolean Matrix Multiplication},
	year = {2002},
	issue_date = {January 2002},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {49},
	number = {1},
	issn = {0004-5411},
	url = {https://doi.org/10.1145/505241.505242},
	doi = {10.1145/505241.505242},
	abstract = {In 1975, Valiant showed that Boolean matrix multiplication can be used for parsing
		context-free grammars (CFGs), yielding the asympotically fastest (although not practical)
		CFG parsing algorithm known. We prove a dual result: any CFG parser with time complexity
		O(gn3-∈), where g is the size of the grammar and n is the length of the input string,
		can be efficiently converted into an algorithm to multiply m \texttimes{} m Boolean matrices
		in time O(m3-∈/3). Given that practical, substantially subcubic Boolean matrix multiplication
		algorithms have been quite difficult to find, we thus explain why there has been little
		progress in developing practical, substantially subcubic general CFG parsers. In proving
		this result, we also develop a formalization of the notion of parsing.},
	journal = {J. ACM},
	month = jan,
	pages = {1–15},
	numpages = {15},
	keywords = {Boolean matrix multiplication, context-free grammar parsing}
}

@article{abboud2018if,
	title={If the current clique algorithms are optimal, so is Valiant's parser},
	author={Abboud, Amir and Backurs, Arturs and Williams, Virginia Vassilevska},
	journal={SIAM Journal on Computing},
	volume={47},
	number={6},
	pages={2527--2555},
	year={2018},
	publisher={SIAM}
}

@article{10.1145/3186893,
	author = {Williams, Virginia Vassilevska and Williams, R. Ryan},
	title = {Subcubic Equivalences Between Path, Matrix, and Triangle Problems},
	year = {2018},
	issue_date = {September 2018},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {65},
	number = {5},
	issn = {0004-5411},
	url = {https://doi.org/10.1145/3186893},
	doi = {10.1145/3186893},
	abstract = {We say an algorithm on n \texttimes{} n matrices with integer entries in [−M,M] (or n-node graphs
		with edge weights from [−M,M]) is truly subcubic if it runs in O(n3 − δ undefined poly(log
		M)) time for some δ &gt; 0. We define a notion of subcubic reducibility and show that
		many important problems on graphs and matrices solvable in O(n3) time are equivalent
		under subcubic reductions. Namely, the following weighted problems either all have
		truly subcubic algorithms, or none of them do:•The all-pairs shortest paths problem
		on weighted digraphs (APSP).•Detecting if a weighted graph has a triangle of negative
		total edge weight.•Listing up to n2.99 negative triangles in an edge-weighted graph.•Finding
		a minimum weight cycle in a graph of non-negative edge weights.•The replacement paths
		problem on weighted digraphs.•Finding the second shortest simple path between two
		nodes in a weighted digraph.•Checking whether a given matrix defines a metric.•Verifying
		the correctness of a matrix product over the (min, +)-semiring.•Finding a maximum
		subarray in a given matrix.Therefore, if APSP cannot be solved in n3−ε time for any
		ε &gt; 0, then many other problems also need essentially cubic time. In fact, we show
		generic equivalences between matrix products over a large class of algebraic structures
		used in optimization, verifying a matrix product over the same structure, and corresponding
		triangle detection problems over the structure. These equivalences simplify prior
		work on subcubic algorithms for all-pairs path problems, since it now suffices to
		give appropriate subcubic triangle detection algorithms.Other consequences of our
		work are new combinatorial approaches to Boolean matrix multiplication over the (OR,AND)-semiring
		(abbreviated as BMM). We show that practical advances in triangle detection would
		imply practical BMM algorithms, among other results. Building on our techniques, we
		give two improved BMM algorithms: a derandomization of the combinatorial BMM algorithm
		of Bansal and Williams (FOCS’09), and an improved quantum algorithm for BMM.},
	journal = {J. ACM},
	month = aug,
	articleno = {27},
	numpages = {38},
	keywords = {all-pairs shortest paths, subcubic time, fine-grained reductions, Fine-grained complexity, equivalences}
}

@inproceedings{10.5555/646233.682379,
	author = {Ruzzo, Walter L.},
	title = {On the Complexity of General Context-Free Language Parsing and Recognition (Extended Abstract)},
	year = {1979},
	isbn = {3540095101},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
	booktitle = {Proceedings of the 6th Colloquium, on Automata, Languages and Programming},
	pages = {489–497},
	numpages = {9}
}

@article{10.1016/j.tcs.2004.05.009,
	author = {Eisenbrand, Friedrich and Grandoni, Fabrizio},
	title = {On the Complexity of Fixed Parameter Clique and Dominating Set},
	year = {2004},
	issue_date = {20 October 2004},
	publisher = {Elsevier Science Publishers Ltd.},
	address = {GBR},
	volume = {326},
	number = {1–3},
	issn = {0304-3975},
	url = {https://doi.org/10.1016/j.tcs.2004.05.009},
	doi = {10.1016/j.tcs.2004.05.009},
	abstract = {We provide simple, faster algorithms for the detection of cliques and dominating sets
		of fixed order. Our algorithms are based on reductions to rectangular matrix multiplication.
		We also describe an improved algorithm for diamonds detection.},
	journal = {Theor. Comput. Sci.},
	month = oct,
	pages = {57–67},
	numpages = {11},
	keywords = {parameterized algorithms, dominating set, diamonds detection, clique}
}

@article{nevsetvril1985complexity,
	title={On the complexity of the subgraph problem},
	author={Ne{\v{s}}et{\v{r}}il, Jaroslav and Poljak, Svatopluk},
	journal={Commentationes Mathematicae Universitatis Carolinae},
	volume={26},
	number={2},
	pages={415--419},
	year={1985},
	publisher={Charles University in Prague, Faculty of Mathematics and Physics}
}

@article{chistikov2021subcubic,
	title={Subcubic Certificates for CFL Reachability},
	author={Chistikov, Dmitry and Majumdar, Rupak and Schepper, Philipp},
	journal={arXiv preprint arXiv:2102.13095},
	year={2021}
}

@article{10.1145/3158118,
	author = {Chatterjee, Krishnendu and Choudhary, Bhavya and Pavlogiannis, Andreas},
	title = {Optimal Dyck Reachability for Data-Dependence and Alias Analysis},
	year = {2017},
	issue_date = {January 2018},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {2},
	number = {POPL},
	url = {https://doi.org/10.1145/3158118},
	doi = {10.1145/3158118},
	abstract = {A fundamental algorithmic problem at the heart of static analysis is Dyck reachability.
		The input is a graph where the edges are labeled with different types of opening and
		closing parentheses, and the reachability information is computed via paths whose
		parentheses are properly matched. We present new results for Dyck reachability problems
		with applications to alias analysis and data-dependence analysis. Our main contributions,
		that include improved upper bounds as well as lower bounds that establish optimality
		guarantees, are as follows: First, we consider Dyck reachability on bidirected graphs,
		which is the standard way of performing field-sensitive points-to analysis. Given
		a bidirected graph with n nodes and m edges, we present: (i)&nbsp;an algorithm with worst-case
		running time O(m + n · α(n)), where α(n) is the inverse Ackermann function, improving
		the previously known O(n2) time bound; (ii)&nbsp;a matching lower bound that shows that
		our algorithm is optimal wrt to worst-case complexity; and (iii)&nbsp;an optimal average-case
		upper bound of O(m) time, improving the previously known O(m · logn) bound. Second,
		we consider the problem of context-sensitive data-dependence analysis, where the task
		is to obtain analysis summaries of library code in the presence of callbacks. Our
		algorithm preprocesses libraries in almost linear time, after which the contribution
		of the library in the complexity of the client analysis is only linear, and only wrt
		the number of call sites. Third, we prove that combinatorial algorithms for Dyck reachability
		on general graphs with truly sub-cubic bounds cannot be obtained without obtaining
		sub-cubic combinatorial algorithms for Boolean Matrix Multiplication, which is a long-standing
		open problem. Thus we establish that the existing combinatorial algorithms for Dyck
		reachability are (conditionally) optimal for general graphs. We also show that the
		same hardness holds for graphs of constant treewidth. Finally, we provide a prototype
		implementation of our algorithms for both alias analysis and data-dependence analysis.
		Our experimental evaluation demonstrates that the new algorithms significantly outperform
		all existing methods on the two problems, over real-world benchmarks.},
	journal = {Proc. ACM Program. Lang.},
	month = dec,
	articleno = {30},
	numpages = {30},
	keywords = {Bidirected graphs, treewidth, CFL reachability, Data-dependence analysis, Dyck reachability}
}

@inbook{inbook,
	author = {Orachev, Egor and Epelbaum, Ilya and Azimov, Rustam and Grigorev, Semyon},
	year = {2020},
	month = {08},
	pages = {49-59},
	title = {Context-Free Path Querying by Kronecker Product},
	isbn = {978-3-030-54831-5},
	doi = {10.1007/978-3-030-54832-2_6}
}

@inproceedings{10.1109/FOCS.2014.53,
	author = {Abboud, Amir and Williams, Virginia Vassilevska},
	title = {Popular Conjectures Imply Strong Lower Bounds for Dynamic Problems},
	year = {2014},
	isbn = {9781479965175},
	publisher = {IEEE Computer Society},
	address = {USA},
	url = {https://doi.org/10.1109/FOCS.2014.53},
	doi = {10.1109/FOCS.2014.53},
	abstract = {We consider several well-studied problems in dynamic algorithms and prove that sufficient
		progress on any of them would imply a breakthrough on one of five major open problems
		in the theory of algorithms: 1) Is the 3SUM problem on n numbers in O(n2 -- \'{y}) time
		for some \'{y} &gt; 0__ __ 2) Can one determine the satisfiability of a CNF formula on n
		variables and poly n clauses in O((2 -- \'{y})npolyn) time for some \'{y} &gt; 0__ __ 3) Is the
		All Pairs Shortest Paths problem for graphs on n vertices in O(n3 -- \'{y}) time for some
		\'{y} &gt; 0__ __ 4) Is there a linear time algorithm that detects whether a given graph
		contains a triangle__ __ 5) Is there an O(n3 -- \'{y}) time combinatorial algorithm for
		n n Boolean matrix multiplication__ __ The problems we consider include dynamic versions
		of bipartite perfect matching, bipartite maximum weight matching, single source reachability,
		single source shortest paths, strong connectivity, subgraph connectivity, diameter
		approximation and some nongraph problems such as Pagh's problem defined in a recent
		paper by p\u{a}tra\c{s}cu [STOC 2010].},
	booktitle = {Proceedings of the 2014 IEEE 55th Annual Symposium on Foundations of Computer Science},
	pages = {434–443},
	numpages = {10},
	keywords = {3SUM, dynamic algorithms, lower bounds, all pairs shortest paths},
	series = {FOCS '14}
}

@inproceedings{bradford2017efficient,
	title={Efficient exact paths for Dyck and semi-Dyck labeled path reachability},
	author={Bradford, Phillip G},
	booktitle={2017 IEEE 8th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference (UEMCON)},
	pages={247--253},
	year={2017},
	organization={IEEE}
}

@article{10.1145/3434315,
	author = {Mathiasen, Anders Alnor and Pavlogiannis, Andreas},
	title = {The Fine-Grained and Parallel Complexity of Andersen’s Pointer Analysis},
	year = {2021},
	issue_date = {January 2021},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {5},
	number = {POPL},
	url = {https://doi.org/10.1145/3434315},
	doi = {10.1145/3434315},
	abstract = {Pointer analysis is one of the fundamental problems in static program analysis. Given
	a set of pointers, the task is to produce a useful over-approximation of the memory
	locations that each pointer may point-to at runtime. The most common formulation is
	Andersen’s Pointer Analysis (APA), defined as an inclusion-based set of m pointer
	constraints over a set of n pointers. Scalability is extremely important, as points-to
	information is a prerequisite to many other components in the static-analysis pipeline.
	Existing algorithms solve APA in O(n2· m) time, while it has been conjectured that
	the problem has no truly sub-cubic algorithm, with a proof so far having remained
	elusive. It is also well-known that APA can be solved in O(n2) time under certain
	sparsity conditions that hold naturally in some settings. Besides these simple bounds,
	the complexity of the problem has remained poorly understood. In this work we draw
	a rich fine-grained and parallel complexity landscape of APA, and present upper and
	lower bounds. First, we establish an O(n3) upper-bound for general APA, improving
	over O(n2· m) as n=O(m). Second, we show that even on-demand APA (“may a specific
	pointer a point to a specific location b?”) has an Ω(n3) (combinatorial) lower bound
	under standard complexity-theoretic hypotheses. This formally establishes the long-conjectured
	“cubic bottleneck” of APA, and shows that our O(n3)-time algorithm is optimal. Third,
	we show that under mild restrictions, APA is solvable in \~{O}(nω) time, where ω&lt;2.373
	is the matrix-multiplication exponent. It is believed that ω=2+o(1), in which case
	this bound becomes quadratic. Fourth, we show that even under such restrictions, even
	the on-demand problem has an Ω(n2) lower bound under standard complexity-theoretic
	hypotheses, and hence our algorithm is optimal when ω=2+o(1). Fifth, we study the
	parallelizability of APA and establish lower and upper bounds: (i) in general, the
	problem is P-complete and hence unlikely parallelizable, whereas (ii) under mild restrictions,
	the problem is parallelizable. Our theoretical treatment formalizes several insights
	that can lead to practical improvements in the future.},
	journal = {Proc. ACM Program. Lang.},
	month = jan,
	articleno = {34},
	numpages = {29},
	keywords = {fine-grained complexity, inclusion-based pointer analysis, Dyck reachability, static pointer analysis}
}

@inproceedings{10.5555/788019.788876,
	author = {Heintze, Nevin and McAllester, David},
	title = {On the Cubic Bottleneck in Subtyping and Flow Analysis},
	year = {1997},
	isbn = {0818679255},
	publisher = {IEEE Computer Society},
	address = {USA},
	abstract = {We prove that certain data-flow and control-flow problems are 2NPDA-complete. This
	means that these problems are in the class 2NPDA and that they are hard for that class.
	The fact that they are in 2NPDA demonstrates the richness of the class. The fact that
	they are hard for 2NPDA can be interpreted as evidence they can not be solved in sub-cubic
	time --- the cubic time decision procedure for an arbitrary 2NPDA problem has not
	been improved since its discovery in 1968.},
	booktitle = {Proceedings of the 12th Annual IEEE Symposium on Logic in Computer Science},
	pages = {342},
	series = {LICS '97}
}

@inproceedings{10.1145/2840728.2840746,
	author = {Carmosino, Marco L. and Gao, Jiawei and Impagliazzo, Russell and Mihajlin, Ivan and Paturi, Ramamohan and Schneider, Stefan},
	title = {Nondeterministic Extensions of the Strong Exponential Time Hypothesis and Consequences for Non-Reducibility},
	year = {2016},
	isbn = {9781450340571},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2840728.2840746},
	doi = {10.1145/2840728.2840746},
	abstract = {We introduce the Nondeterministic Strong Exponential Time Hypothesis (NSETH) as a
	natural extension of the Strong Exponential Time Hypothesis (SETH). We show that both
	refuting and proving NSETH would have interesting consequences.In particular we show
	that disproving NSETH would give new nontrivial circuit lower bounds. On the other
	hand, NSETH implies non-reducibility results, i.e. the absence of (deterministic)
	fine-grained reductions from SAT to a number of problems. As a consequence we conclude
	that unless this hypothesis fails, problems such as 3-SUM, APSP and model checking
	of a large class of first-order graph properties cannot be shown to be SETH-hard using
	deterministic or zero-error probabilistic reductions.},
	booktitle = {Proceedings of the 2016 ACM Conference on Innovations in Theoretical Computer Science},
	pages = {261–270},
	numpages = {10},
	keywords = {computational complexity, conditional lower bounds, 3-sum, nondeterminism, fine-grained complexity, all-pairs shortest path, seth},
	location = {Cambridge, Massachusetts, USA},
	series = {ITCS '16}
}

@article{Hanauer2020FasterFD,
	title={Faster Fully Dynamic Transitive Closure in Practice},
	author={Kathrin Hanauer and Monika Henzinger and Christian Schulz},
	journal={ArXiv},
	year={2020},
	volume={abs/2002.00813}
}

@article{10.1145/258994.259006,
	author = {Melski, David and Reps, Thomas},
	title = {Interconvertbility of Set Constraints and Context-Free Language Reachability},
	year = {1997},
	issue_date = {Dec. 1997},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {32},
	number = {12},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/258994.259006},
	doi = {10.1145/258994.259006},
	abstract = {We show the interconvertibility of context-free-language reachability problems and
	a class of set-constraint problems: given a context-free-language reachability problem,
	we show how to construct a set-constraint problem whose answer gives a solution to
	the reachability problem; given a set-constraint problem, we show how to construct
	a context-free-language reachability problem whose answer gives a solution to the
	set-constraint problem. The interconvertibility of these two formalisms offers an
	conceptual advantage akin to the advantage gained from the interconvertibility of
	finite-state automata and regular expressions in formal language theory, namely, a
	problem can be formulated in whichever formalism is most natural. It also offers some
	insight into the "O(n3) bottleneck" for different types of program-analysis problems,
	and allows results previously obtained for context-free-language reachability problems
	to be applied to set-constraint problems.},
	journal = {SIGPLAN Not.},
	month = dec,
	pages = {74–89},
	numpages = {16}
}

@inproceedings{bringmann2019fine,
	title={Fine-Grained Complexity Theory},
	author={Bringmann, Karl},
	booktitle={36th International Symposium on Theoretical Aspects of Computer Science},
	pages={1},
	year={2019}
}

@inproceedings{10.1145/360204.360208,
	author = {Rehof, Jakob and F\"{a}hndrich, Manuel},
	title = {Type-Base Flow Analysis: From Polymorphic Subtyping to CFL-Reachability},
	year = {2001},
	isbn = {1581133367},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/360204.360208},
	doi = {10.1145/360204.360208},
	abstract = {We present a novel approach to scalable implementation of type-based flow analysis
	with polymorphic subtyping. Using a new presentation of polymorphic subytping with
	instantiation constraints, we are able to apply context-free language (CFL) reachability
	techniques to type-based flow analysis. We develop a CFL-based algorithm for computing
	flow-information in time O(n³), where n is the size of the typed program. The
	algorithm substantially improves upon the best previously known algorithm for flow
	analysis based on polymorphic subtyping with complexity O(n8). Our technique also
	yields the first demand-driven algorithm for polymorphic subtype-based flow-computation.
	It works directly on higher-order programs with structured data of finite type (unbounded
	data structures are incorporated via finite approximations), supports context-sensitive,
	global flow summariztion and includes polymorphic recursion.},
	booktitle = {Proceedings of the 28th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
	pages = {54–66},
	numpages = {13},
	location = {London, United Kingdom},
	series = {POPL '01}
}

@article{10.1145/373243.360208,
	author = {Rehof, Jakob and F\"{a}hndrich, Manuel},
	title = {Type-Base Flow Analysis: From Polymorphic Subtyping to CFL-Reachability},
	year = {2001},
	issue_date = {March 2001},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {36},
	number = {3},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/373243.360208},
	doi = {10.1145/373243.360208},
	abstract = {We present a novel approach to scalable implementation of type-based flow analysis
	with polymorphic subtyping. Using a new presentation of polymorphic subytping with
	instantiation constraints, we are able to apply context-free language (CFL) reachability
	techniques to type-based flow analysis. We develop a CFL-based algorithm for computing
	flow-information in time O(n³), where n is the size of the typed program. The
	algorithm substantially improves upon the best previously known algorithm for flow
	analysis based on polymorphic subtyping with complexity O(n8). Our technique also
	yields the first demand-driven algorithm for polymorphic subtype-based flow-computation.
	It works directly on higher-order programs with structured data of finite type (unbounded
	data structures are incorporated via finite approximations), supports context-sensitive,
	global flow summariztion and includes polymorphic recursion.},
	journal = {SIGPLAN Not.},
	month = jan,
	pages = {54–66},
	numpages = {13}
}

@inproceedings{10.1145/1094811.1094817,
	author = {Sridharan, Manu and Gopan, Denis and Shan, Lexin and Bod\'{\i}k, Rastislav},
	title = {Demand-Driven Points-to Analysis for Java},
	year = {2005},
	isbn = {1595930310},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1094811.1094817},
	doi = {10.1145/1094811.1094817},
	abstract = {We present a points-to analysis technique suitable for environments with small time
	and memory budgets, such as just-in-time (JIT) compilers and interactive development
	environments (IDEs). Our technique is demand-driven, performing only the work necessary
	to answer each query (a request for a variable's points-to information) issued by
	a client. In cases where even the demand-driven approach exceeds the time budget for
	a query, we employ early termination, i.e., stopping the analysis prematurely and
	returning an over-approximated result to the client. Our technique improves on previous
	demand-driven points-to analysis algorithms [17, 33] by achieving much higher precision
	under small time budgets and early termination.We formulate Andersen's analysis [5]
	for Java as a CFL-reachability problem [33]. This formulation shows that Andersen's
	analysis for Java is a balanced-parentheses problem, an insight that enables our new
	techniques. We exploit the balanced parentheses structure to approximate Andersen's
	analysis by regularizing the CFL-reachability problem, yielding an asymptotically
	cheaper algorithm. We also show how to regain most of the precision lost in the regular
	approximation as needed through refinement. Our evaluation shows that our regularization
	and refinement approach achieves nearly the precision of field-sensitive Andersen's
	analysis in time budgets as small as 2ms per query. Our technique can yield speedups
	of up to 16x over computing an exhaustive Andersen's analysis for some clients, with
	little to no precision loss.},
	booktitle = {Proceedings of the 20th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications},
	pages = {59–76},
	numpages = {18},
	keywords = {points-to analysis, context-free language reachability, refinement, demand-driven analysis},
	location = {San Diego, CA, USA},
	series = {OOPSLA '05}
}

@article{10.1145/1103845.1094817,
	author = {Sridharan, Manu and Gopan, Denis and Shan, Lexin and Bod\'{\i}k, Rastislav},
	title = {Demand-Driven Points-to Analysis for Java},
	year = {2005},
	issue_date = {October 2005},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {40},
	number = {10},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/1103845.1094817},
	doi = {10.1145/1103845.1094817},
	abstract = {We present a points-to analysis technique suitable for environments with small time
	and memory budgets, such as just-in-time (JIT) compilers and interactive development
	environments (IDEs). Our technique is demand-driven, performing only the work necessary
	to answer each query (a request for a variable's points-to information) issued by
	a client. In cases where even the demand-driven approach exceeds the time budget for
	a query, we employ early termination, i.e., stopping the analysis prematurely and
	returning an over-approximated result to the client. Our technique improves on previous
	demand-driven points-to analysis algorithms [17, 33] by achieving much higher precision
	under small time budgets and early termination.We formulate Andersen's analysis [5]
	for Java as a CFL-reachability problem [33]. This formulation shows that Andersen's
	analysis for Java is a balanced-parentheses problem, an insight that enables our new
	techniques. We exploit the balanced parentheses structure to approximate Andersen's
	analysis by regularizing the CFL-reachability problem, yielding an asymptotically
	cheaper algorithm. We also show how to regain most of the precision lost in the regular
	approximation as needed through refinement. Our evaluation shows that our regularization
	and refinement approach achieves nearly the precision of field-sensitive Andersen's
	analysis in time budgets as small as 2ms per query. Our technique can yield speedups
	of up to 16x over computing an exhaustive Andersen's analysis for some clients, with
	little to no precision loss.},
	journal = {SIGPLAN Not.},
	month = oct,
	pages = {59–76},
	numpages = {18},
	keywords = {points-to analysis, refinement, context-free language reachability, demand-driven analysis}
}


@inproceedings{10.1145/1133981.1134027,
	author = {Sridharan, Manu and Bod\'{\i}k, Rastislav},
	title = {Refinement-Based Context-Sensitive Points-to Analysis for Java},
	year = {2006},
	isbn = {1595933204},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1133981.1134027},
	doi = {10.1145/1133981.1134027},
	abstract = {We present a scalable and precise context-sensitive points-to analysis with three
	key properties: (1) filtering out of unrealizable paths, (2) a context-sensitive heap
	abstraction, and (3) a context-sensitive call graph. Previous work [21] has shown
	that all three properties are important for precisely analyzing large programs, e.g.,
	to show safety of downcasts. Existing analyses typically give up one or more of the
	properties for scalability. We have developed a refinement-based analysis that succeeds
	by simultaneously refining handling of method calls and heap accesses, allowing the
	analysis to precisely analyze important code while entirely skipping irrelevant code.
	The analysis is demanddriven and client-driven, facilitating refinement specific to
	each queried variable and increasing scalability. In our experimental evaluation,
	our analysis proved the safety of 61% more casts than one of the most precise existing
	analyses across a suite of large benchmarks. The analysis checked the casts in under
	13 minutes per benchmark (taking less than 1 second per query) and required only 35MB
	of memory, far less than previous approaches.},
	booktitle = {Proceedings of the 27th ACM SIGPLAN Conference on Programming Language Design and Implementation},
	pages = {387–400},
	numpages = {14},
	keywords = {demand-driven analysis, context-sensitive analysis, points-to analysis, refinement},
	location = {Ottawa, Ontario, Canada},
	series = {PLDI '06}
}

@article{10.1145/1133255.1134027,
	author = {Sridharan, Manu and Bod\'{\i}k, Rastislav},
	title = {Refinement-Based Context-Sensitive Points-to Analysis for Java},
	year = {2006},
	issue_date = {June 2006},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {41},
	number = {6},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/1133255.1134027},
	doi = {10.1145/1133255.1134027},
	abstract = {We present a scalable and precise context-sensitive points-to analysis with three
	key properties: (1) filtering out of unrealizable paths, (2) a context-sensitive heap
	abstraction, and (3) a context-sensitive call graph. Previous work [21] has shown
	that all three properties are important for precisely analyzing large programs, e.g.,
	to show safety of downcasts. Existing analyses typically give up one or more of the
	properties for scalability. We have developed a refinement-based analysis that succeeds
	by simultaneously refining handling of method calls and heap accesses, allowing the
	analysis to precisely analyze important code while entirely skipping irrelevant code.
	The analysis is demanddriven and client-driven, facilitating refinement specific to
	each queried variable and increasing scalability. In our experimental evaluation,
	our analysis proved the safety of 61% more casts than one of the most precise existing
	analyses across a suite of large benchmarks. The analysis checked the casts in under
	13 minutes per benchmark (taking less than 1 second per query) and required only 35MB
	of memory, far less than previous approaches.},
	journal = {SIGPLAN Not.},
	month = jun,
	pages = {387–400},
	numpages = {14},
	keywords = {context-sensitive analysis, demand-driven analysis, points-to analysis, refinement}
}


@inproceedings{10.1145/298514.298576,
	author = {Yannakakis, Mihalis},
	title = {Graph-Theoretic Methods in Database Theory},
	year = {1990},
	isbn = {0897913523},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/298514.298576},
	doi = {10.1145/298514.298576},
	booktitle = {Proceedings of the Ninth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems},
	pages = {230–242},
	numpages = {13},
	location = {Nashville, Tennessee, USA},
	series = {PODS '90}
}

@inproceedings{10.1145/1328438.1328460,
	author = {Chaudhuri, Swarat},
	title = {Subcubic Algorithms for Recursive State Machines},
	year = {2008},
	isbn = {9781595936899},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1328438.1328460},
	doi = {10.1145/1328438.1328460},
	abstract = {We show that the reachability problem for recursive state machines (or equivalently,
	pushdown systems), believed for long to have cubic worst-case complexity, can be solved
	in slightly subcubic time. All that is necessary for the new bound is a simple adaptation
	of a known technique. We also show that a better algorithm exists if the input machine
	does not have infinite recursive loops.},
	booktitle = {Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
	pages = {159–169},
	numpages = {11},
	keywords = {transitive closure, CFL-reachability, interprocedural analysis, context-free languages, cubic bottleneck, recursive state machines, pushdown systems},
	location = {San Francisco, California, USA},
	series = {POPL '08}
}

@inproceedings{10.1145/199448.199462,
	author = {Reps, Thomas and Horwitz, Susan and Sagiv, Mooly},
	title = {Precise Interprocedural Dataflow Analysis via Graph Reachability},
	year = {1995},
	isbn = {0897916921},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/199448.199462},
	doi = {10.1145/199448.199462},
	abstract = {The paper shows how a large class of interprocedural dataflow-analysis problems can
	be solved precisely in polynomial time by transforming them into a special kind of
	graph-reachability problem. The only restrictions are that the set of dataflow facts
	must be a finite set, and that the dataflow functions must distribute over the confluence
	operator (either union or intersection). This class of probable problems includes—but
	is not limited to—the classical separable problems (also known as “gen/kill” or “bit-vector”
	problems)—e.g., reaching definitions, available expressions, and live variables. In
	addition, the class of problems that our techniques handle includes many non-separable
	problems, including truly-live variables, copy constant propagation, and possibly-uninitialized
	variables.Results are reported from a preliminary experimental study of C programs
	(for the problem of finding possibly-uninitialized variables).},
	booktitle = {Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
	pages = {49–61},
	numpages = {13},
	location = {San Francisco, California, USA},
	series = {POPL '95}
}

@inproceedings{10.5555/3039686.3039828,
	author = {Larsen, Kasper Green and Williams, Ryan},
	title = {Faster Online Matrix-Vector Multiplication},
	year = {2017},
	publisher = {Society for Industrial and Applied Mathematics},
	address = {USA},
	abstract = {We consider the Online Boolean Matrix-Vector Multiplication (OMV) problem studied
	by Henzinger et al. [STOC'15]: given an n \texttimes{} n Boolean matrix M, we receive n Boolean
	vectors v1,...,vn one at a time, and are required to output Mvi (over the Boolean
	semiring) before seeing the vector vi+1, for all i. Previous known algorithms for
	this problem are combinatorial, running in O(n3 /log2 n) time. Henzinger et al. conjecture
	there is no O(n3−ε) time algorithm for OMV, for all ε &gt; 0; their OMV conjecture is
	shown to imply strong hardness results for many basic dynamic problems.We give a substantially
	faster method for computing OMV, running in [EQUATION] randomized time. In fact, after
	seeing [EQUATION] vectors, we already achieve [EQUATION] amortized time for matrix-vector
	multiplication. Our approach gives a way to reduce matrix-vector multiplication to
	solving a version of the Orthogonal Vectors problem, which in turn reduces to "small"
	algebraic matrix-matrix multiplication. Applications include faster independent set
	detection, partial match retrieval, and 2-CNF evaluation.We also show how a modification
	of our method gives a cell probe data structure for OMV with worst case [EQUATION]
	time per query vector, where w is the word size. This result rules out an unconditional
	proof of the OMV conjecture using purely information-theoretic arguments.},
	booktitle = {Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms},
	pages = {2182–2189},
	numpages = {8},
	location = {Barcelona, Spain},
	series = {SODA '17}
}

@inproceedings{10.1145/2746539.2746609,
	author = {Henzinger, Monika and Krinninger, Sebastian and Nanongkai, Danupon and Saranurak, Thatchaphol},
	title = {Unifying and Strengthening Hardness for Dynamic Problems via the Online Matrix-Vector Multiplication Conjecture},
	year = {2015},
	isbn = {9781450335362},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2746539.2746609},
	doi = {10.1145/2746539.2746609},
	abstract = {Consider the following Online Boolean Matrix-Vector Multiplication problem: We are
	given an n x n matrix M and will receive n column-vectors of size n, denoted by v1,
	..., vn, one by one. After seeing each vector vi, we have to output the product Mvi
	before we can see the next vector. A naive algorithm can solve this problem using
	O(n3) time in total, and its running time can be slightly improved to O(n3/log2 n)
	[Williams SODA'07]. We show that a conjecture that there is no truly subcubic (O(n3-ε))
	time algorithm for this problem can be used to exhibit the underlying polynomial time
	hardness shared by many dynamic problems. For a number of problems, such as subgraph
	connectivity, Pagh's problem, d-failure connectivity, decremental single-source shortest
	paths, and decremental transitive closure, this conjecture implies tight hardness
	results. Thus, proving or disproving this conjecture will be very interesting as it
	will either imply several tight unconditional lower bounds or break through a common
	barrier that blocks progress with these problems. This conjecture might also be considered
	as strong evidence against any further improvement for these problems since refuting
	it will imply a major breakthrough for combinatorial Boolean matrix multiplication
	and other long-standing problems if the term "combinatorial algorithms" is interpreted
	as "Strassen-like algorithms" [Ballard et al. SPAA'11].The conjecture also leads to
	hardness results for problems that were previously based on diverse problems and conjectures
	-- such as 3SUM, combinatorial Boolean matrix multiplication, triangle detection,
	and multiphase -- thus providing a uniform way to prove polynomial hardness results
	for dynamic algorithms; some of the new proofs are also simpler or even become trivial.
	The conjecture also leads to stronger and new, non-trivial, hardness results, e.g.,
	for the fully-dynamic densest subgraph and diameter problems.},
	booktitle = {Proceedings of the Forty-Seventh Annual ACM Symposium on Theory of Computing},
	pages = {21–30},
	numpages = {10},
	keywords = {lower bounds, dynamic graph algorithms},
	location = {Portland, Oregon, USA},
	series = {STOC '15}
}

@misc{shemetova2021algorithm,
	title={One Algorithm to Evaluate Them All: Unified Linear Algebra Based Approach to Evaluate Both Regular and Context-Free Path Queries}, 
	author={Ekaterina Shemetova and Rustam Azimov and Egor Orachev and Ilya Epelbaum and Semyon Grigorev},
	year={2021},
	eprint={2103.14688},
	archivePrefix={arXiv},
	primaryClass={cs.DB}
}

@INPROCEEDINGS{8948597,  
	author={van den Brand, Jan and Nanongkai, Danupon and Saranurak, Thatchaphol},  
	booktitle={2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS)},   
	title={Dynamic Matrix Inverse: Improved Algorithms and Matching Conditional Lower Bounds},   
	year={2019},  
	volume={},  
	number={},  
	pages={456-480},  
	doi={10.1109/FOCS.2019.00036}}

@article{REPS1998701,
	title = {Program analysis via graph reachability1An abbreviated version of this paper appeared as an invited paper in the Proceedings of the 1997 International Symposium on Logic Programming [84].1},
	journal = {Information and Software Technology},
	volume = {40},
	number = {11},
	pages = {701-726},
	year = {1998},
	issn = {0950-5849},
	doi = {https://doi.org/10.1016/S0950-5849(98)00093-7},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584998000937},
	author = {Thomas Reps},
	abstract = {This paper describes how a number of program-analysis problems can be solved by transforming them to graph-reachability problems. Some of the program-analysis problems that are amenable to this treatment include program slicing, certain dataflow-analysis problems, one version of the problem of approximating the possible “shapes” that heap-allocated structures in a program can take on, and flow-insensitive points-to analysis. Relationships between graph reachability and other approaches to program analysis are described. Some techniques that go beyond pure graph reachability are also discussed.}
}
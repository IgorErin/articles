@book{GAILLA,
author = {Kepner, Jeremy and Gilbert, John},
title = {Graph Algorithms in the Language of Linear Algebra},
year = {2011},
isbn = {0898719909},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {Graphs are among the most important abstract data types in computer science, and the algorithms that operate on them are critical to modern life. Graphs have been shown to be powerful tools for modeling complex problems because of their simplicity and generality. Graph algorithms are one of the pillars of mathematics, informing research in such diverse areas as combinatorial optimization, complexity theory, and topology. Algorithms on graphs are applied in many ways in today s world - from Web rankings to metabolic networks, from finite element meshes to semantic graphs. The current exponential growth in graph data has forced a shift to parallel computing for executing graph algorithms. Implementing parallel graph algorithms and achieving good parallel performance have proven difficult. This book addresses these challenges by exploiting the well-known duality between a canonical representation of graphs as abstract collections of vertices and edges and a sparse adjacency matrix representation. This linear algebraic approach is widely accessible to scientists and engineers who may not be formally trained in computer science. The authors show how to leverage existing parallel matrix computation techniques and the large amount of software infrastructure that exists for these computations to implement efficient and scalable parallel graph algorithms. The benefits of this approach are reduced algorithmic complexity, ease of implementation, and improved performance. Graph Algorithms in the Language of Linear Algebra is the first book to cover graph algorithms accessible to engineers and scientists not trained in computer science but having a strong linear algebra background, enabling them to quickly understand and apply graph algorithms. It also covers array-based graph algorithms, showing readers how to express canonical graph algorithms using a highly elegant and efficient array notation and how to tap into the large range of tools and techniques that have been built for matrices and tensors; parallel array-based algorithms, demonstrating with examples how to easily implement parallel graph algorithms using array-based approaches, which enables readers to address much larger graph problems; and array-based theory for analyzing graphs, providing a template for using array-based constructs to develop new theoretical approaches for graph analysis. Audience: This book is suitable as the primary text for a class on linear algebraic graph algorithms and as either the primary or supplemental text for a class on graph algorithms for engineers and scientists without training in computer science. Contents: List of Figures; List of Tables; List of Algorithms; Preface; Acknowledgments; Part I: Algorithms: Chapter 1: Graphs and Matrices; Chapter 2: Linear Algebraic Notation and Definitions; Chapter 3: Connected Components and Minimum Paths; Chapter 4: Some Graph Algorithms in an Array-Based Language; Chapter 5: Fundamental Graph Algorithms; Chapter 6: Complex Graph Algorithms; Chapter 7: Multilinear Algebra for Analyzing Data with Multiple Linkages; Chapter 8: Subgraph Detection; Part II: Data: Chapter 9: Kronecker Graphs; Chapter 10: The Kronecker Theory of Power Law Graphs; Chapter 11: Visualizing Large Kronecker Graphs; Part III: Computation: Chapter 12: Large-Scale Network Analysis; Chapter 13: Implementing Sparse Matrices for Graph Algorithms; Chapter 14: New Ideas in Sparse Matrix-Matrix Multiplication; Chapter 15: Parallel Mapping of Sparse Computations; Chapter 16: Fundamental Questions in the Analysis of Large Graphs; Index.}
}

@article{buluc2017graphblas,
  title={The GraphBLAS C API Specification},
  author={Buluc, Aydin and Mattson, Timothy and McMillan, Scott and Moreira, Jose and Yang, Carl},
  journal={GraphBLAS. org, Tech. Rep.},
  year={2017}
}

@misc{yang2020graphblast,
      title={GraphBLAST: A High-Performance Linear Algebra-based Graph Framework on the GPU}, 
      author={Carl Yang and Aydin Buluc and John D. Owens},
      year={2020},
      eprint={1908.01407},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}
@article{KernelFusion,
   title={Optimizing CUDA code by kernel fusion: application on BLAS},
   volume={71},
   ISSN={1573-0484},
   url={http://dx.doi.org/10.1007/s11227-015-1483-z},
   DOI={10.1007/s11227-015-1483-z},
   number={10},
   journal={The Journal of Supercomputing},
   publisher={Springer Science and Business Media LLC},
   author={Filipovič, Jiří and Madzin, Matúš and Fousek, Jan and Matyska, Luděk},
   year={2015},
   month={Jul},
   pages={3934–3957}
}

@inproceedings{10.1145/3062341.3062354,
author = {Henriksen, Troels and Serup, Niels G. W. and Elsman, Martin and Henglein, Fritz and Oancea, Cosmin E.},
title = {Futhark: Purely Functional GPU-Programming with Nested Parallelism and in-Place Array Updates},
year = {2017},
isbn = {9781450349888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3062341.3062354},
doi = {10.1145/3062341.3062354},
abstract = { Futhark is a purely functional data-parallel array language that offers a machine-neutral programming model and an optimising compiler that generates OpenCL code for GPUs.  This paper presents the design and implementation of three key features of Futhark that seek a suitable middle ground with imperative approaches.  First, in order to express efficient code inside the parallel constructs, we introduce a simple type system for in-place updates that ensures referential transparency and supports equational reasoning.  Second, we furnish Futhark with parallel operators capable of expressing efficient strength-reduced code, along with their fusion rules.  Third, we present a flattening transformation aimed at enhancing the degree of parallelism that (i) builds on loop interchange and distribution but uses higher-order reasoning rather than array-dependence analysis, and (ii) still allows further locality-of-reference optimisations. Finally, an evaluation on 16 benchmarks demonstrates the impact of the language and compiler features and shows application-level performance competitive with hand-written GPU code. },
booktitle = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {556–571},
numpages = {16},
keywords = {compilers, functional language, parallel, GPGPU},
location = {Barcelona, Spain},
series = {PLDI 2017}
}

@article{Futhark,
author = {Henriksen, Troels and Serup, Niels G. W. and Elsman, Martin and Henglein, Fritz and Oancea, Cosmin E.},
title = {Futhark: Purely Functional GPU-Programming with Nested Parallelism and in-Place Array Updates},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/3140587.3062354},
doi = {10.1145/3140587.3062354},
abstract = { Futhark is a purely functional data-parallel array language that offers a machine-neutral programming model and an optimising compiler that generates OpenCL code for GPUs.  This paper presents the design and implementation of three key features of Futhark that seek a suitable middle ground with imperative approaches.  First, in order to express efficient code inside the parallel constructs, we introduce a simple type system for in-place updates that ensures referential transparency and supports equational reasoning.  Second, we furnish Futhark with parallel operators capable of expressing efficient strength-reduced code, along with their fusion rules.  Third, we present a flattening transformation aimed at enhancing the degree of parallelism that (i) builds on loop interchange and distribution but uses higher-order reasoning rather than array-dependence analysis, and (ii) still allows further locality-of-reference optimisations. Finally, an evaluation on 16 benchmarks demonstrates the impact of the language and compiler features and shows application-level performance competitive with hand-written GPU code. },
journal = {SIGPLAN Not.},
month = jun,
pages = {556–571},
numpages = {16},
keywords = {parallel, functional language, compilers, GPGPU}
}



@inproceedings{CUDADMA,
author = {Bauer, Michael and Cook, Henry and Khailany, Brucek},
title = {CudaDMA: Optimizing GPU Memory Bandwidth via Warp Specialization},
year = {2011},
isbn = {9781450307710},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2063384.2063400},
doi = {10.1145/2063384.2063400},
abstract = {As the computational power of GPUs continues to scale with Moore's Law, an increasing number of applications are becoming limited by memory bandwidth. We propose an approach for programming GPUs with tightly-coupled specialized DMA warps for performing memory transfers between on-chip and off-chip memories. Separate DMA warps improve memory bandwidth utilization by better exploiting available memory-level parallelism and by leveraging efficient inter-warp producer-consumer synchronization mechanisms. DMA warps also improve programmer productivity by decoupling the need for thread array shapes to match data layout. To illustrate the benefits of this approach, we present an extensible API, CudaDMA, that encapsulates synchronization and common sequential and strided data transfer patterns. Using CudaDMA, we demonstrate speedup of up to 1.37x on representative synthetic microbenchmarks, and 1.15x-3.2x on several kernels from scientific applications written in CUDA running on NVIDIA Fermi GPUs.},
booktitle = {Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {12},
numpages = {11},
location = {Seattle, Washington},
series = {SC '11}
}

@article{Song_2016,
   title={Novel graph processor architecture, prototype system, and results},
   ISBN={9781509035250},
   url={http://dx.doi.org/10.1109/HPEC.2016.7761635},
   DOI={10.1109/hpec.2016.7761635},
   journal={2016 IEEE High Performance Extreme Computing Conference (HPEC)},
   publisher={IEEE},
   author={Song, William S. and Gleyzer, Vitaliy and Lomakin, Alexei and Kepner, Jeremy},
   year={2016},
   month={Sep}
}

@misc{leskovec2016snap,
      title={SNAP: A General Purpose Network Analysis and Graph Mining Library}, 
      author={Jure Leskovec and Rok Sosic},
      year={2016},
      eprint={1606.07550},
      archivePrefix={arXiv},
      primaryClass={cs.SI}
}

@article{Florida,
author = {Davis, Timothy A. and Hu, Yifan},
title = {The University of Florida Sparse Matrix Collection},
year = {2011},
issue_date = {November 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0098-3500},
url = {https://doi.org/10.1145/2049662.2049663},
doi = {10.1145/2049662.2049663},
abstract = {We describe the University of Florida Sparse Matrix Collection, a large and actively growing set of sparse matrices that arise in real applications. The Collection is widely used by the numerical linear algebra community for the development and performance evaluation of sparse matrix algorithms. It allows for robust and repeatable experiments: robust because performance results with artificially generated matrices can be misleading, and repeatable because matrices are curated and made publicly available in many formats. Its matrices cover a wide spectrum of domains, include those arising from problems with underlying 2D or 3D geometry (as structural engineering, computational fluid dynamics, model reduction, electromagnetics, semiconductor devices, thermodynamics, materials, acoustics, computer graphics/vision, robotics/kinematics, and other discretizations) and those that typically do not have such geometry (optimization, circuit simulation, economic and financial modeling, theoretical and quantum chemistry, chemical process simulation, mathematics and statistics, power networks, and other networks and graphs). We provide software for accessing and managing the Collection, from MATLAB™, Mathematica™, Fortran, and C, as well as an online search capability. Graph visualization of the matrices is provided, and a new multilevel coarsening scheme is proposed to facilitate this task.},
journal = {ACM Trans. Math. Softw.},
month = dec,
articleno = {1},
numpages = {25},
keywords = {multilevel algorithms, Graph drawing, sparse matrices, performance evaluation}
}

 @inproceedings{zhang2020sparch,
    title     = {SpArch: Efficient Architecture for Sparse Matrix Multiplication},
    author    = {Zhang, Zhekai and Wang, Hanrui and Han, Song and Dally, William J.},
    booktitle = {26th IEEE International Symposium on High Performance Computer Architecture (HPCA)},
    year      = {2020}
} 

@inproceedings{Systolic,
author = {He, Xin and Pal, Subhankar and Amarnath, Aporva and Feng, Siying and Park, Dong-Hyeon and Rovinski, Austin and Ye, Haojie and Chen, Yuhan and Dreslinski, Ronald and Mudge, Trevor},
title = {Sparse-TPU: Adapting Systolic Arrays for Sparse Matrices},
year = {2020},
isbn = {9781450379830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3392717.3392751},
doi = {10.1145/3392717.3392751},
abstract = {While systolic arrays are widely used for dense-matrix operations, they are seldom used for sparse-matrix operations. In this paper, we show how a systolic array of Multiply-and-Accumulate (MAC) units, similar to Google's Tensor Processing Unit (TPU), can be adapted to efficiently handle sparse matrices. TPU-like accelerators are built upon a 2D array of MAC units and have demonstrated high throughput and efficiency for dense matrix multiplication, which is a key kernel in machine learning algorithms and is the target of the TPU. In this work, we employ a co-designed approach of first developing a packing technique to condense a sparse matrix and then propose a systolic array based system, Sparse-TPU, abbreviated to STPU, to accommodate the matrix computations for the packed denser matrix counterparts. To demonstrate the efficacy of our co-designed approach, we evaluate sparse matrix-vector multiplication on a broad set of synthetic and real-world sparse matrices. Experimental results show that STPU delivers 16.08X higher performance while consuming 4.39X and 19.79X lower energy for integer (int8) and floating point (float32) implementations, respectively, over a TPU baseline. Meanwhile, STPU has 12.93% area overhead and an average of 4.14% increase in dynamic energy over the TPU baseline for the float32 implementation.},
booktitle = {Proceedings of the 34th ACM International Conference on Supercomputing},
articleno = {19},
numpages = {12},
keywords = {sparse matrix condensing, hardware-software codesign, hardware accelerators, application-specific hardware, systolic array, sparse matrix processing},
location = {Barcelona, Spain},
series = {ICS '20}
}

@misc{CPU-FPGA,
      title={Synergistic CPU-FPGA Acceleration of Sparse Linear Algebra}, 
      author={Mohammadreza Soltaniyeh and Richard P. Martin and Santosh Nagarakatte},
      year={2020},
      eprint={2004.13907},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@misc{compBio,
      title={Distributed Many-to-Many Protein Sequence Alignment using Sparse Matrices}, 
      author={Oguz Selvitopi and Saliya Ekanayake and Giulia Guidi and Georgios Pavlopoulos and Ariful Azad and Aydin Buluc},
      year={2020},
      eprint={2009.14467},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@article{Kepner_2017,
   title={Enabling massive deep neural networks with the GraphBLAS},
   ISBN={9781538634721},
   url={http://dx.doi.org/10.1109/HPEC.2017.8091098},
   DOI={10.1109/hpec.2017.8091098},
   journal={2017 IEEE High Performance Extreme Computing Conference (HPEC)},
   publisher={IEEE},
   author={Kepner, Jeremy and Kumar, Manoj and Moreira, Jose and Pattnaik, Pratap and Serrano, Mauricio and Tufo, Henry},
   year={2017},
   month={Sep}
}

@book{jones,
author = {Jones, Neil D. and Gomard, Carsten K. and Sestoft, Peter},
title = {Partial Evaluation and Automatic Program Generation},
year = {1993},
isbn = {0130202495},
publisher = {Prentice-Hall, Inc.},
address = {USA}
}

@article{10.1145/1291220.1291199,
author = {Coutts, Duncan and Leshchinskiy, Roman and Stewart, Don},
title = {Stream Fusion: From Lists to Streams to Nothing at All},
year = {2007},
issue_date = {September 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/1291220.1291199},
doi = {10.1145/1291220.1291199},
abstract = {This paper presents an automatic deforestation system, stream fusion, based on equational transformations, that fuses a wider range of functions than existing short-cut fusion systems. In particular, stream fusion is able to fuse zips, left folds and functions over nested lists, including list comprehensions. A distinguishing feature of the framework is its simplicity: by transforming list functions to expose their structure, intermediate values are eliminated by general purpose compiler optimisations.We have reimplemented the Haskell standard List library on top of our framework, providing stream fusion for Haskell lists. By allowing a wider range of functions to fuse, we see an increase in the number of occurrences of fusion in typical Haskell programs. We present benchmarks documenting time and space improvements.},
journal = {SIGPLAN Not.},
month = oct,
pages = {315–326},
numpages = {12},
keywords = {program transformation, program fusion, program optimisation, deforestation, functional programming}
}

@inproceedings{fusion,
author = {Coutts, Duncan and Leshchinskiy, Roman and Stewart, Don},
title = {Stream Fusion: From Lists to Streams to Nothing at All},
year = {2007},
isbn = {9781595938152},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291151.1291199},
doi = {10.1145/1291151.1291199},
abstract = {This paper presents an automatic deforestation system, stream fusion, based on equational transformations, that fuses a wider range of functions than existing short-cut fusion systems. In particular, stream fusion is able to fuse zips, left folds and functions over nested lists, including list comprehensions. A distinguishing feature of the framework is its simplicity: by transforming list functions to expose their structure, intermediate values are eliminated by general purpose compiler optimisations.We have reimplemented the Haskell standard List library on top of our framework, providing stream fusion for Haskell lists. By allowing a wider range of functions to fuse, we see an increase in the number of occurrences of fusion in typical Haskell programs. We present benchmarks documenting time and space improvements.},
booktitle = {Proceedings of the 12th ACM SIGPLAN International Conference on Functional Programming},
pages = {315–326},
numpages = {12},
keywords = {program transformation, program optimisation, deforestation, program fusion, functional programming},
location = {Freiburg, Germany},
series = {ICFP '07}
}


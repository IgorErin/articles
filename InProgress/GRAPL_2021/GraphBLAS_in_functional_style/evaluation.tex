\section{Evaluation}

While our project\footnote{GraphBLAS\# project page: \url{https://github.com/YaccConstructor/GraphBLAS-sharp}.} is in a very early stage we implemented and evaluated only generic matrix-matrix element-wise function \texttt{map2} to demonstrate that the proposed solution may provide not only a way to an expressive compact high-level API, but also a way to its high-performance implementation. This function implemented for matrices in CSR format. We use Brahma.FSharp to support GPGPUs.  

We evaluate \texttt{map2} function parameterized by two operations: \texttt{op\_int\_add} (listing~\ref{lst:opIntAdd}) to get element-wise addition in terms of GraphBLAS API, and \texttt{op\_int\_mult} (listing~\ref{lst:opIntMult}) to get element-wise multiplication.

\subsection{Environment}
We perform our experiments on the PC with Ubuntu 18.04 installed and with the following hardware configuration: !!! CPU, !!! RAM, !!!GPGPU with !!!!.

For comparison we choose a SuiteSparse:GraphBLAS as a reference CPU implementation of GraphBLAS API, and CUSP\footnote{Cusp is a CUDA-based library for sparse linear algebra and graph computations: \url{https://cusplibrary.github.io/}.} as a most stable GPGPU implementation of generic sparse linear algebra.

\begin{table}[H]
    \centering
    \caption{Matrices for evaluation}
    \label{matrices}  
    \begin{tabular}{ | c || c | c | c | }
    \hline
    Matrix & Size & NNZ & Squared matrix NNZ \\ \hline
    \hline
    wing & 62 032 & 243 088 & 714,200 \\ \hline
    luxembourg\_osm & 114 599 & 119 666 & 4 582 \\ \hline
    amazon0312 & 400 727 & 3 200 440 & 14 390 544 \\ \hline
    amazon-2008 & 735 323 & 5 158 388 & 25 366 745 \\ \hline
    web-Google & 916 428 & 5 105 039 & 30 811 855 \\ \hline
    webbase-1M & 1 000 005 & 3 105 536 & 51 111 996 \\ \hline
    cit-Patents & 3 774 768 & 16 518 948 & 469 \\ \hline
    \end{tabular}
\end{table}


\subsection {Dataset}

For evaluation we select a set of matrices from SuiteSparse matrix collection\footnote{SuiteSparse matrix collection: \url{https://sparse.tamu.edu/}.}
To simplify evaluation of element-wise operations over matrices with different structure we precompute square of each matrix. 
Characteristics of selected matrices are presented in table~\ref{matrices}.

\subsection{Evaluation Results}

\begin{table*}[h]
    \centering    
    \caption{Evaluation results for element-wise operations, time in ms}    
    \label{perf-comparison}
    \begin{tabular}{|c||c|c|c|c||c|c|}
    \hline
    \multirow{3}{*}{Matrix} & \multicolumn{4}{c||}{Elemint-wise addition} & \multicolumn{2}{c|}{Elemint-wise multiplication}\\    
    \cline{2-7}        
    & \multicolumn{2}{c|}{GraphBLAS-sharp} & \multirow{2}{*}{SuiteSparse} & \multirow{2}{*}{CUSP} & \multirow{2}{*}{GraphBLAS-sharp} & \multirow{2}{*}{SuiteSparse}        \\
    &No \texttt{AtLeastOne}&\texttt{AtLeastOne}& & & &\\ 
    \hline
    \hline
    wing            & $1,6 \pm 0,3$       & $1,5 \pm 0,2$      & $1,9\pm 0,1$   & $0,5\pm 0,2$   & $2,5 \pm 0,4$       & $1,0 \pm 0,1$\\
    \hline
    luxembourg\_osm & $2,0 \pm 0,3$       & $2,0 \pm 0,3$      & $1.9\pm 0,5$   & $0,5\pm 0,1$  & $2,6 \pm 0,3$       & $1,4 \pm 0,3$ \\
    \hline
    amazon0312      & $9,1 \pm 0,8$       & $9,2 \pm 0,8$     & $28,9\pm 0,2$  & $2,8\pm 0,1$  & $13,0 \pm 1,0$      & $23,0 \pm 0,9$ \\
    \hline
    amazon-2008     & $7,2 \pm 0,7$       & $7,0 \pm 0,6$     & $50,1\pm 2,4$  & $3,5\pm 0,1$ & $9,1 \pm 0,8$       & $35,2 \pm 4,0$  \\
    \hline
    web-Google      & $9,8 \pm 0,9$       & $9,3 \pm 0,6$     & $58.8\pm 0,7$  & $3,6\pm 0,1$  & $14,7 \pm 0,8$      & $43,9 \pm 0,2$ \\
    \hline
    webbase-1M      & $58,2 \pm 1,1$      & $58,0 \pm 1,0$      & $72,9\pm 0,4$  & $24,6\pm 2,1$  & $55,4 \pm 1,2$      & $31,0 \pm 1,6$ \\
    \hline
    cit-Patents     & $26,1 \pm 1,0$      & $25,5 \pm 0,9$      & $157,4\pm 1,2$ & $8,5\pm 1,2$   & $47,9 \pm 0,9$      & $107,9 \pm 0,4$ \\     
    \hline
    \end{tabular}    
\end{table*}

To benchmark .NET-based implementation we use \textit{BenchmarkDotNet}\footnote{\textit{BenchmarkDotNet}: \url{https://benchmarkdotnet.org/}. Access date: 12.06.2022.} which allows one to automate benchmarking process for .NET platform.
We run each function XXX times, !!!
Time is measured in milliseconds. The time to prepare data and initially transfer it to GPU is not included.

Results of performance evaluation are presented in table~\ref{perf-comparison}.
We can see, that for element-wise addition our implementation slower than SuiteSparse:GraphBLAS for small matrices (\textbf{luxembourg\_osm}) and up to 4 times faster for big matrices. !!! CUSP !!!
For element-wise multiplication results are almost similar except matrix \textbf{webbase-1M} for which our implementation slower than SuiteSparse:GraphBLAS while this matrix contains big number of non-zero values.

Comparison between original element-wise addition over primitive types, without \texttt{AtLeasOne} and generalized version which uses \texttt{AtLeastOne} type is also presented in table~\ref{perf-comparison}.
We can see, that more complex data types and element-wise operations do not poor performance of matrix-matrix operations. The reason for such behavior is that data transfer dominates arithmetic computations for sparse matrices processing, and the proposed abstraction does not increase the memory footprint.

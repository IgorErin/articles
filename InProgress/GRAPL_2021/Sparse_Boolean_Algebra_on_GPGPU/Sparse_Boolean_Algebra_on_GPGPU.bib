@article{10.5555/972525.972527,
author = {Satta, Giorgio},
title = {Tree-Adjoining Grammar Parsing and Boolean Matrix Multiplication},
year = {1994},
issue_date = {June 1994},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {20},
number = {2},
issn = {0891-2017},
abstract = {The computational problem of parsing a sentence in a tree-adjoining language is investigated. An interesting relation is studied between this problem and the well-known computational problem of Boolean matrix multiplication: it is shown that any algorithm for the solution of the former problem can easily be converted into an algorithm for the solution of the latter problem. This result bears on at least two important computational issues. First, we realize that a straightforward method that improves the known upper bound for tree-adjoining grammar parsing is hard to find. Second, we understand which features of the tree-adjoining grammar parsing problem are responsible for the claimed difficulty.},
journal = {Comput. Linguist.},
month = jun,
pages = {173--191},
numpages = {19}
}


% High-performance and Memory-saving Sparse General Matrix-Matrix Multiplication for NVIDIA Pascal GPU
@INPROCEEDINGS{algo:spgemm:8025284,
  author={Y. {Nagasaka} and A. {Nukada} and S. {Matsuoka}},
  booktitle={2017 46th International Conference on Parallel Processing (ICPP)}, 
  title={High-Performance and Memory-Saving Sparse General Matrix-Matrix Multiplication for NVIDIA Pascal GPU}, 
  year={2017},
  volume={},
  number={},
  pages={101-110},
  doi={10.1109/ICPP.2017.19}
}

% Sparse matrix-matrix multiplication framework
@article{DBLP:journals/corr/0002V15a:spframework,
  author    = {Weifeng Liu and
               Brian Vinter},
  title     = {A Framework for General Sparse Matrix-Matrix Multiplication on GPUs
               and Heterogeneous Processors},
  journal   = {CoRR},
  volume    = {abs/1504.05022},
  year      = {2015},
  url       = {http://arxiv.org/abs/1504.05022},
  archivePrefix = {arXiv},
  eprint    = {1504.05022},
  timestamp = {Mon, 13 Aug 2018 16:48:39 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/0002V15a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Latest matrix-based cfpq for redis graph with single-source semantic
@inproceedings{inproceedings:cfpq_for_redis_graph,
  author = {Terekhov, Arseniy and Khoroshev, Artyom and Azimov, Rustam and Grigorev, Semyon},
  title = {Context-Free Path Querying with Single-Path Semantics by Matrix Multiplication},
  year = {2020},
  isbn = {9781450380218},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3398682.3399163},
  doi = {10.1145/3398682.3399163},
  abstract = {A recent study showed that the applicability of context-free path querying (CFPQ) algorithms with relational query semantics integrated with graph databases is limited because of low performance and high memory consumption of existing solutions. In this work, we implement a matrix-based CFPQ algorithm by using appropriate high-performance libraries for linear algebra and integrate it with RedisGraph graph database. Also, we introduce a new CFPQ algorithm with single-path query semantics that allows us to extract one found path for each pair of nodes. Finally, we provide the evaluation of our algorithms for both semantics which shows that matrix-based CFPQ implementation for Redis-Graph database is performant enough for real-world data analysis.},
  booktitle = {Proceedings of the 3rd Joint International Workshop on Graph Data Management Experiences; Systems (GRADES) and Network Data Analytics (NDA)},
  articleno = {5},
  numpages = {12},
  keywords = {Boolean matrix, transitive closure, GPGPU, context-free grammar, Context-free path querying, matrix multiplication, linear algebra, RedisGraph database, CUDA, graph databases},
  location = {Portland, OR, USA},
  series = {GRADES-NDA'20}
}

% GPU Merge path
@inproceedings{inproceedings:gpu_merge_path,
  author = {Green, Oded and McColl, Robert and Bader, David A.},
  title = {GPU Merge Path: A GPU Merging Algorithm},
  year = {2012},
  isbn = {9781450313162},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2304576.2304621},
  doi = {10.1145/2304576.2304621},
  abstract = {Graphics Processing Units (GPUs) have become ideal candidates for the development of fine-grain parallel algorithms as the number of processing elements per GPU increases. In addition to the increase in cores per system, new memory hierarchies and increased bandwidth have been developed that allow for significant performance improvement when computation is performed using certain types of memory access patterns.Merging two sorted arrays is a useful primitive and is a basic building block for numerous applications such as joining database queries, merging adjacency lists in graphs, and set intersection. An efficient parallel merging algorithm partitions the sorted input arrays into sets of non-overlapping sub-arrays that can be independently merged on multiple cores. For optimal performance, the partitioning should be done in parallel and should divide the input arrays such that each core receives an equal size of data to merge.In this paper, we present an algorithm that partitions the workload equally amongst the GPU Streaming Multi-processors (SM). Following this, we show how each SM performs a parallel merge and how to divide the work so that all the GPU's Streaming Processors (SP) are utilized. All stages in this algorithm are parallel. The new algorithm demonstrates good utilization of the GPU memory hierarchy. This approach demonstrates an average of 20X and 50X speedup over a sequential merge on the x86 platform for integer and floating point, respectively. Our implementation is 10X faster than the fast parallel merge supplied in the CUDA Thrust library.},
  booktitle = {Proceedings of the 26th ACM International Conference on Supercomputing},
  pages = {331–340},
  numpages = {10},
  keywords = {graphics processors, measurement of multiple-processor systems, parallel algorithms, parallel systems},
  location = {San Servolo Island, Venice, Italy},
  series = {ICS '12}
}

% About dcsr
@INPROCEEDINGS{4536313:about:dcsr,  
  author={A. {Buluc} and J. R. {Gilbert}},  
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing},   
  title={On the representation and multiplication of hypersparse matrices},   
  year={2008},  
  volume={},  
  number={},  
  pages={1-11},  
  doi={10.1109/IPDPS.2008.4536313}
}

@article{OKHOTIN2014101,
title = "Parsing by matrix multiplication generalized to Boolean grammars",
journal = "Theoretical Computer Science",
volume = "516",
pages = "101--120",
year = "2014",
issn = "0304-3975",
doi = "https://doi.org/10.1016/j.tcs.2013.09.011",
url = "http://www.sciencedirect.com/science/article/pii/S0304397513006919",
author = "Alexander Okhotin",
keywords = "Boolean grammars, Conjunctive grammars, Context-free grammars, Matrix multiplication, Parsing",
abstract = "The well-known parsing algorithm for context-free grammars due to Valiant (1975) [25] is analyzed and extended to handle the more general Boolean grammars, which are context-free grammars augmented with conjunction and negation operators in the rules. The algorithm reduces construction of a parsing table to computing multiple products of Boolean matrices of various sizes. Its time complexity on an input string of length n is O(BMM(n)logn), where BMM(n) is the number of operations needed to multiply two Boolean matrices of size n×n, which is O(nω) with ω<2.373 as per the current knowledge. A parse tree can be constructed in time MM(n)logO(1)n (where MM(n) is the complexity of multiplying two integer matrices), by applying a known efficient procedure for determining witnesses for Boolean matrix multiplication. The algorithm has a succinct proof of correctness and is ready to be implemented."
}

@INPROCEEDINGS{7761646,
author={J. {Kepner} and P. {Aaltonen} and D. {Bader} and A. {Buluc} and F. {Franchetti} and J. {Gilbert} and D. {Hutchison} and M. {Kumar} and A. {Lumsdaine} and H. {Meyerhenke} and S. {McMillan} and C. {Yang} and J. D. {Owens} and M. {Zalewski} and T. {Mattson} and J. {Moreira}},
booktitle={2016 IEEE High Performance Extreme Computing Conference (HPEC)},
title={Mathematical foundations of the GraphBLAS},
year={2016},
volume={},
number={},
pages={1--9},
keywords={graph theory;mathematics computing;matrix algebra;programming environments;mathematical foundations;GraphBLAS standard;GraphBlas.org;matrix-based graph algorithms;matrix-based graph operations;programming environments;adjacency matrices;incidence matrices;matrix multiplication;matrix mathematics;Matrices;Sparse matrices;Finite element analysis;Standards;Additives},
doi={10.1109/HPEC.2016.7761646},
ISSN={},
month={Sep.},}

@INPROCEEDINGS{8091098,
  author={J. {Kepner} and M. {Kumar} and J. {Moreira} and P. {Pattnaik} and M. {Serrano} and H. {Tufo}},
  booktitle={2017 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Enabling massive deep neural networks with the GraphBLAS}, 
  year={2017},
  volume={},
  number={},
  pages={1--10},
  doi={10.1109/HPEC.2017.8091098}}

@inproceedings{10.5555/3433701.3433800,
author = {Selvitopi, Oguz and Ekanayake, Saliya and Guidi, Giulia and Pavlopoulos, Georgios A. and Azad, Ariful and Bulu\c{c}, Ayd\i{}n},
title = {Distributed Many-to-Many Protein Sequence Alignment Using Sparse Matrices},
year = {2020},
isbn = {9781728199986},
publisher = {IEEE Press},
abstract = {Identifying similar protein sequences is a core step in many computational biology pipelines such as detection of homologous protein sequences, generation of similarity protein graphs for downstream analysis, functional annotation, and gene location. Performance and scalability of protein similarity search have proven to be a bottleneck in many bioinformatics pipelines due to increase in cheap and abundant sequencing data. This work presents a new distributed-memory software PASTIS. PASTIS relies on sparse matrix computations for efficient identification of possibly similar proteins. We use distributed sparse matrices for scalability and show that the sparse matrix infrastructure is a great fit for protein similarity search when coupled with a fully-distributed dictionary of sequences that allow remote sequence requests to be fulfilled. Our algorithm incorporates the unique bias in amino acid sequence substitution in search without altering basic sparse matrix model, and in turn, achieves ideal scaling up to millions of protein sequences.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {75},
numpages = {14},
location = {Atlanta, Georgia},
series = {SC '20}
}

@article{yang2019graphblast,
  title = {{GraphBLAST}: A High-Performance Linear Algebra-based Graph Framework on the {GPU}},
  author = {Carl Yang and Ayd{\i}n Bulu{\c{c}} and John D. Owens},
  year = {2019},
  journal = {arXiv preprint},
  arxiv = {https://arxiv.org/abs/1908.01407}
}

@article{Gao2020ASS,
  title={A Systematic Survey of General Sparse Matrix-Matrix Multiplication},
  author={J. Gao and W. Ji and Zhaonian Tan and Yueyan Zhao},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.11273}
}

@inproceedings{10.1145/2909437.2909442,
author = {Greathouse, Joseph L. and Knox, Kent and Po\l{}a, Jakub and Varaganti, Kiran and Daga, Mayank},
title = {ClSPARSE: A Vendor-Optimized Open-Source Sparse BLAS Library},
year = {2016},
isbn = {9781450343381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2909437.2909442},
doi = {10.1145/2909437.2909442},
abstract = {Sparse linear algebra is a cornerstone of modern computational science. These algorithms ignore the zero-valued entries found in many domains in order to work on much larger problems at much faster rates than dense algorithms. Nonetheless, optimizing these algorithms is not straightforward. Highly optimized algorithms for multiplying a sparse matrix by a dense vector, for instance, are the subject of a vast corpus of research and can be hundreds of times longer than na\"{\i}ve implementations. Optimized sparse linear algebra libraries are thus needed so that users can build applications without enormous effort.Hardware vendors release proprietary libraries that are highly optimized for their devices, but they limit interoperability and promote vendor lock-in. Open libraries often work across multiple devices and can quickly take advantage of new innovations, but they may not reach peak performance. The goal of this work is to provide a sparse linear algebra library that offers both of these advantages.We thus describe clSPARSE, a permissively licensed open-source sparse linear algebra library that offers state-of-the-art optimized algorithms implemented in OpenCL™. We test clSPARSE on GPUs from AMD and Nvidia and show performance benefits over both the proprietary cuSPARSE library and the open-source ViennaCL library.},
booktitle = {Proceedings of the 4th International Workshop on OpenCL},
articleno = {7},
numpages = {4},
keywords = {GPGPU, OpenCL, Sparse Linear Algebra, clSPARSE},
location = {Vienna, Austria},
series = {IWOCL '16}
}

@article{10.1016/S0022-0000(75)80046-8,
author = {Valiant, Leslie G.},
title = {General Context-Free Recognition in Less than Cubic Time},
year = {1975},
issue_date = {April, 1975},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {10},
number = {2},
issn = {0022-0000},
url = {https://doi.org/10.1016/S0022-0000(75)80046-8},
doi = {10.1016/S0022-0000(75)80046-8},
abstract = {An algorithm for general context-free recognition is given that requires less than n3 time asymptotically for input strings of length n.},
journal = {J. Comput. Syst. Sci.},
month = apr,
pages = {308--315},
numpages = {8}
}

@inproceedings{10.1145/3210259.3210264,
author = {Azimov, Rustam and Grigorev, Semyon},
title = {Context-Free Path Querying by Matrix Multiplication},
year = {2018},
isbn = {9781450356954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210259.3210264},
doi = {10.1145/3210259.3210264},
abstract = {Context-free path querying is a technique, which recently gains popularity in many areas, for example, graph databases, bioinformatics, static analysis, etc. In some of these areas, it is often required to query large graphs, and existing algorithms demonstrate a poor performance in this case. The generalization of matrix-based Valiant's context-free language recognition algorithm for graph case is widely considered as a recipe for efficient context-free path querying; however, no progress has been made in this direction so far.We propose the first generalization of matrix-based Valiant's algorithm for context-free path querying. Our generalization does not deliver a truly sub-cubic worst-case complexity algorithm, whose existence still remains a hard open problem in the area. On the other hand, the utilization of matrix operations (such as matrix multiplication) in the process of context-free path query evaluation makes it possible to efficiently apply a wide class of optimizations and computing techniques, such as GPGPU (General-Purpose computing on Graphics Processing Units), parallel processing, sparse matrix representation, distributed-memory computation, etc. Indeed, the evaluation on a set of conventional benchmarks shows, that our algorithm outperforms the existing ones.},
booktitle = {Proceedings of the 1st ACM SIGMOD Joint International Workshop on Graph Data Management Experiences \& Systems (GRADES) and Network Data Analytics (NDA)},
articleno = {5},
numpages = {10},
keywords = {matrix multiplication, graph databases, context-free grammar, GPGPU, transitive closure, context-free path querying},
location = {Houston, Texas},
series = {GRADES-NDA '18}
}

@article{10.1016/j.jpdc.2015.06.010,
author = {Liu, Weifeng and Vinter, Brian},
title = {A Framework for General Sparse Matrix-Matrix Multiplication on GPUs and Heterogeneous Processors},
year = {2015},
issue_date = {November 2015},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {85},
number = {C},
issn = {0743-7315},
url = {https://doi.org/10.1016/j.jpdc.2015.06.010},
doi = {10.1016/j.jpdc.2015.06.010},
abstract = {General sparse matrix-matrix multiplication (SpGEMM) is a fundamental building block for numerous applications such as algebraic multigrid method (AMG), breadth first search and shortest path problem. Compared to other sparse BLAS routines, an efficient parallel SpGEMM implementation has to handle extra irregularity from three aspects: (1) the number of nonzero entries in the resulting sparse matrix is unknown in advance, (2) very expensive parallel insert operations at random positions in the resulting sparse matrix dominate the execution time, and (3) load balancing must account for sparse data in both input matrices.In this work we propose a framework for SpGEMM on GPUs and emerging CPU-GPU heterogeneous processors. This framework particularly focuses on the above three problems. Memory pre-allocation for the resulting matrix is organized by a hybrid method that saves a large amount of global memory space and efficiently utilizes the very limited on-chip scratchpad memory. Parallel insert operations of the nonzero entries are implemented through the GPU merge path algorithm that is experimentally found to be the fastest GPU merge approach. Load balancing builds on the number of necessary arithmetic operations on the nonzero entries and is guaranteed in all stages.Compared with the state-of-the-art CPU and GPU SpGEMM methods, our approach delivers excellent absolute performance and relative speedups on various benchmarks multiplying matrices with diverse sparsity structures. Furthermore, on heterogeneous processors, our SpGEMM approach achieves higher throughput by using re-allocatable shared virtual memory. We design a framework for SpGEMM on modern manycore processors using the CSR format.We present a hybrid method for pre-allocating the resulting sparse matrix.We propose an efficient parallel insert method for long rows of the resulting matrix.We develop a heuristic-based load balancing strategy.Our approach significantly outperforms other known CPU and GPU SpGEMM methods.},
journal = {J. Parallel Distrib. Comput.},
month = nov,
pages = {47--61},
numpages = {15},
keywords = {Linear algebra, Sparse matrix, Sparse matrix-matrix multiplication, Heterogeneous processor, GPU, Merging, Parallel algorithm}
}
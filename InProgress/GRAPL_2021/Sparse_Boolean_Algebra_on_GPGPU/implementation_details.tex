\section{Implementation Details}

In this section we discuss the particular implementation details of the proposed libraries.
Although general structure and architecture are similar, the internal storage formats and algorithms are different.
With this development strategy, we address the potential problem of processing the sparse data with different values distribution, as well as the problem of proper balancing between time of the execution and memory consumption.

\subsection{Library cuBool}

cuBool\footnote{cuBool project: \url{https://github.com/JetBrains-Research/cuBool}. Access date: 10.02.2021.}
is a sparse boolean linear algebra implementation developed specially for NVIDIA Cuda platform.
The core of this library relies on Cuda C language and API.
%, \cho{what with NVCC compiler allows intermix C++ with Cuda specifics}.
Also cuBool employs NVIDIA Thrust auxiliary library, which provides implementation for generic data containers and operations, such as \textit{iterating}, \textit{exclusive or inclusive scan}, \textit{map}, etc., which are executed on Cuda device.
The algorithms can be expressed in terms of high-level optimized primitives, which increases code readability and reduces time for development.

Sparse matrices are stored in the \textit{compressed sparse row} (CSR) format with only two arrays: $rowspt$ for row offset indices and $cols$ for columns indices.
There is no need to store any values in boolean sparse matrices, thus $1$ values are encoded only as $(i, j)$ pairs.
This means that it is possible to store a matrix $M$ of size $m \times n$ in $(m + \textit{nnz(M)}) \times \textit{sizeof(index\_t)}$ bytes of GPU memory, where \textit{index\_t} is the type of stored indices, which can be selected to be \textit{uint32\_t} for simplicity.

We use the algorithm Nspasrse~\cite{inproceedings:cfpq_for_redis_graph} for matrix-matrix multiplication.
This algorithm is an adaptation of the state-of-the-art, efficient and memory saving sparse general matrix multiplication (SpGEMM) algorithm, proposed in Yusuke Nagasaka et al. research~\cite{algo:spgemm:8025284} for boolean values.
This algorithm was selected because it has a relatively small memory footprint for large matrices processing, as well as it competes with other major Cuda SpGEMM implementations, such as cuSPARSE or CUSP.

Matrix-matrix addition is based on GPU Merge Path algorithm~\cite{inproceedings:gpu_merge_path} with dynamic work balancing and two pass processing.
These optimizations give better workload dispatch among execution blocks and allow for more precise memory allocations in order to keep memory footprint small.

% As an example of library C API embedding, cuBool provides python wrapper, called Pycubool. This module exports
% library functionality via default CTypes module for native functions calling and provides safe and automated
% management for native resources.

\subsection{Library clBool}

clBool\footnote{clBool project: \url{https://github.com/mkarpenkospb/sparse_boolean_matrix_operations}. Access date: 10.02.2021.} 
is a sparse boolean linear algebra implementation for OpenCL platform.
This library is implemented in C++ with OpenCL kernels, packed into executable code at compile time. 

Sparse matrix primitive is stored in the \textit{coordinate format} (COO) with two arrays: $rows$ and $cols$ for row and column indices of the stored non-zero values.
For the matrix $M$ of size $m \times n$, the memory consumption is $2 \times \textit{nnz(M)} \times \textit{sizeof(index\_t)}$.
This format was selected instead of CSR, because COO gives better memory footprint for very sparse matrices with many empty rows.

Matrix-matrix multiplication implementation is based on the algorithm, proposed in the paper by Weifeng Liu et al.~\cite{DBLP:journals/corr/0002V15a:spframework}.
It is a multi-step algorithm with dynamic workload balancing which operates on CSR matrices.
This algorithm is suitable for OpenCL implementation, which is confirmed by its utilization in clSPARSE library.
Input matrices are converted from COO into \textit{doubly compressed sparse row} (DCSR) format,
because a redundant COO rows array slows down the rows indexing process. 
% Since clBool primary primitive is COO matrix, the input matrices are converted into \textit{doubly compressed sparse row} (DCSR) format, described in A. Buluc et al. work~\cite{4536313:about:dcsr}, before matrix-matrix multiplication.

% Matrix-matrix addition is based on the GPU Merge Path algorithm as well.
% % Since all COO matrix values are stored continuously, its merge can be completed \cho{at single time}, whereas the matrix merge in CSR is computed on a per row basis.
% It is implemented in the classic fashion: it allocates a single merge buffer of size $\textit{nnz(A)} + \textit{nnz(B)}$ before the actual merge of matrices $A$ and $B$, what can negatively affect the memory consumption for large matrices with lots of duplicated non-zero values at the same positions.
Matrix-matrix addition is based on the GPU Merge Path algorithm as well.
Since all COO matrix values are stored continuously, 
its addition can be treated as the merge of two sorted arrays, 
whereas the matrix merge in CSR is computed on a per row basis. 
This operation is implemented in two steps: merge and duplicates reduce. 
In the first step it allocates a single merge buffer of size $\textit{nnz(A)} + \textit{nnz(B)}$, 
where merge result is stored with possible duplicates. 
% Then we reduce duplicates using scan, and finally copy the unique values at their actual positions. 
Although this approach is simple and straightforward, it can negatively affect the memory consumption for large matrices with lots of duplicated non-zero values at the same positions.

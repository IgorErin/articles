\section{Evaluation}

% Evaluation of the proposed implemenation(s).

% What we need:
% - idea of the evaluation
% - what we want to show and measure
% - time performance, memory consumption, ops/per sec
% - what data we need?
% - very sparse, different distributions

We evaluate the applicability of the proposed libraries for analysis of some real-world matrix data.
The experiments are designed as computational tasks, that arise as stand-alone or intermediate steps in the solving of practical problems.

For evaluation, we used a PC with Ubuntu 20.04 installed.
It has Intel core i7-4790 CPU, 3.6GHz, DDR4 32Gb RAM and GeForce GTX 1070 GPU with 8Gb VRAM.
We measure only the execution time of the operations themselves.
The actual data is assumed to be loaded into the VRAM or RAM respectively in the appropriate format, required for the target tested framework.
Time to load data from the disc and prepare initial matrices state is excluded from the time measurements.

We use four sparse matrix libraries, CUSP, cuSPARSE, clSPARSE for GPU and SuiteSparse for CPU.
CUSP provides a template based implementation for operations, however it does not provide extra optimizations especially for boolean case values. cuSPARSE and clSPARSE both provide operations only for general types, such as float or double.
However this limitation can be ignored, if we consider non-zero float values as \textit{true}.
SuiteSparse is a GraphBLAS API reference implementation for CPU with built-in boolean semiring.

For performance evaluations, we selected $10$ various square matrices, which are widely used for sparse matrices benchmarks, from the Sparse Matrix Collection at University of Florida\footnote{T. Davis. The SuiteSparse Matrix Collection (the University of Florida Sparse Matrix Collection). Home page: \url{https://sparse.tamu.edu/}. Access date: 10.02.2021.}.
Information about matrices is summarized in table~\ref{table:sparse_matrices}.

{\setlength{\tabcolsep}{0.3em}
\begin{table}
\centering
{
\caption{Sparse matrix data for evaluation.}
\label{table:sparse_matrices}
\scriptsize
\rowcolors{2}{black!2}{black!10}
\begin{tabular}{|c|l|c|c|c|c|}
\hline
\textnumero&Matrix $M$           & $\# Rows$    & Nnz of $M$   & Nnz of $M^2$   & Nnz of $M + M^2$ \\
\hline
\hline
0&  wing             &    62,032    &   243,088    &    714,200     &    917,178       \\
1&  luxembourg\_osm  &   114,599    &   239,332    &    393,261     &    632,185       \\
2&  amazon0312       &   400,727    & 3,200,400    & 14,390,544     & 14,968,909       \\
3&  amazon-2008      &   735,323    & 5,158,388    & 25,366,745     & 26,402,678       \\
4&  web-Google       &   916,428    & 5,105,039    & 29,710,164     & 30,811,855       \\
5&  roadNet-PA       & 1,090,920    & 3,083,796    &  7,238,920     &  9,931,528       \\
6&  roadNet-TX       & 1,393,383    & 3,843,320    &  8,903,897     & 12,264,987       \\
7&  belgium\_osm     & 1,441,295    & 3,099,940    &  5,323,073     &  8,408,599       \\
8&  roadNet-CA       & 1,971,281    & 5,533,214    & 12,908,450     & 17,743,342       \\
9&  netherlands\_osm & 2,216,688    & 4,882,476    &  8,755,758     & 13,626,132       \\ 
\hline
\end{tabular}
}
\end{table}
}

The results of the evaluation are summarized in tables~\ref{table:eval_mm_results} and~\ref{table:eval_ma_results}.
Time is measured in milliseconds. 
Peak VRAM memory usage is measured in megabytes.
The result for each experiment is averaged over 10 runs.
The cell is left blank if the operation is not implemented by a library.

The first experiment is intended to measure the performance of the matrix-matrix multiplication as $M \times M$.
The results are presented in the table~\ref{table:eval_mm_results}.
We can see that cuBool shows nearly best performance among competitors.
clBool has good performance as well, comparable to major Cuda competitors or clSPARSE in some cases.  
However, CUSP and clSPRASE have significant memory consumption,
which can negatively affect on processing of large data.

The second experiment is intended to measure performance of the element-wise matrix-matrix addition as $M + M^2$,
where evaluation of the matrix $M^2$ is excluded from measurements.
The results are presented in the table~\ref{table:eval_ma_results}.
The numbers obtained in this experiment are more ambiguous than in the previous experiment.
cuBool, CUSP and cuSPARSE show best performance among almost all runs.
Memory consumption for cuBool is relatively small compared to CUSP and cuSPARSE. 
clBool generally keeps its results within acceptable limits.
However, it still lags behind SuiteSparse. 
There is still space for optimizations, 
so it requires a deep investigation in our future research.

% It is worth mentioning, that CUSP matrix-matrix addition implementation has significant memory consumption, which can negatively affect on processing of huge data.
% cuSPARSE performance can degrade in such case as well, since its implementation is based on hashing, which is very sensitive for out-of shared blocks memory access for large data processing.

{\setlength{\tabcolsep}{0.25em}
\begin{table}[t]
\centering
{
\caption{Matrix-matrix multiplication evaluation results\\(Time in milliseconds, Memory in megabytes).}
\label{table:eval_mm_results}
\scriptsize
\rowcolors{4}{black!2}{black!10}
\begin{tabular}{| c | c c | c c | c c | c c | c c | c |}
\hline
$M$ & \multicolumn{2}{c|}{CuBool} & \multicolumn{2}{c|}{CUSP} & \multicolumn{2}{c|}{CuSprs} & \multicolumn{2}{c|}{ClBool} & \multicolumn{2}{c|}{ClSprs} & \multicolumn{1}{c|}{SuiteSprs} \\   
\textnumero& Time  & Mem & Time  & Mem  & Time   & Mem & Time  & Mem & Time  & Mem  & Time  \\
\hline
\hline
0           & 2.2  & 215 & 5.8   & 125  & 20.2   & 155 & 60.5  & 95  & 127.9 & 109  & 10.0  \\ % 1.  wing             
1           & 2.9  & 213 & 4.1   & 111  & 1.7    & 149 & 16.0  & 91  & 10.8  & 99   & 2.5   \\ % 2.  luxembourg\_osm  
2           & 24.6 & 215 & 110.3 & 897  & 411.6  & 301 & 97.6  & 279 & 65.7  & 459  & 238.2 \\ % 3.  amazon0312       
3           & 38.9 & 341 & 173.5 & 1409 & 182.8  & 407 & 110.1 & 401 & 104.4 & 701  & 339.4 \\ % 4.  amazon-2008      
4           & 50.1 & 341 & 240.8 & 1717 & 4756.4 & 439 & 277.8 & 491 & 409.2 & 1085 & 644.6 \\ % 5.  web-Google       
5           & 21.7 & 215 & 43.3  & 481  & 37.6   & 247 & 45.6  & 203 & 85.5  & 283  & 63.0  \\ % 6.  roadNet-PA       
6           & 26.6 & 215 & 52.1  & 581  & 46.8   & 271 & 55.8  & 229 & 107.4 & 329  & 74.9  \\ % 7.  roadNet-TX       
7           & 26.9 & 215 & 33.8  & 397  & 26.7   & 235 & 68.6  & 183 & 104.9 & 259  & 57.8  \\ % 8.  belgium\_osm     
8           & 37.6 & 215 & 76.4  & 771  & 67.2   & 325 & 77.7  & 279 & 151.5 & 433  & 110.5 \\ % 9.  roadNet-CA       
9           & 40.4 & 215 & 51.9  & 585  & 51.1   & 291 & 78.1  & 251 & 158.2 & 361  & 93.0  \\ % 10. netherlands\_osm  
\hline
\end{tabular}
}
\end{table}
}

{\setlength{\tabcolsep}{0.25em}
\begin{table}[t]
\centering
{
\caption{Element-wise matrix-matrix addition evaluation results\\(Time in milliseconds, Memory in megabytes).}
\label{table:eval_ma_results}
\scriptsize
\rowcolors{4}{black!2}{black!10}
\begin{tabular}{| c | c c | c c | c c | c c | c c | c |}
\hline
$M$ & \multicolumn{2}{c|}{CuBool} & \multicolumn{2}{c|}{CUSP} & \multicolumn{2}{c|}{CuSprs} & \multicolumn{2}{c|}{ClBool} & \multicolumn{2}{c|}{ClSprs} & \multicolumn{1}{c|}{SuiteSprs} \\   
\textnumero & Time & Mem & Time & Mem & Time & Mem & Time  & Mem & Time & Mem & Time \\
\hline
\hline
0           & 1.1  & 97  & 1.5  & 103 & 2.4  & 163 & 22.8  & 105 & -    & -   & 4.0  \\ % 1.  wing             
1           & 1.7  & 103 & 1.1  & 103 & 0.9  & 159 & 4.5   & 103 & -    & -   & 1.5  \\ % 2.  luxembourg\_osm  
2           & 9.4  & 237 & 16.5 & 455 & 24.1 & 405 & 84.0  & 543 & -    & -   & 35.1 \\ % 3.  amazon0312       
3           & 16.2 & 347 & 29.1 & 723 & 23.6 & 595 & 163.3 & 877 & -    & -   & 61.2 \\ % 4.  amazon-2008      
4           & 18.7 & 379 & 32.3 & 815 & 88.7 & 659 & 176.7 & 989 & -    & -   & 72.5 \\ % 5.  web-Google       
5           & 15.4 & 207 & 11.6 & 329 & 11.8 & 317 & 66.4  & 359 & -    & -   & 34.0 \\ % 6.  roadNet-PA       
6           & 19.3 & 231 & 14.0 & 385 & 14.7 & 357 & 73.2  & 429 & -    & -   & 41.8 \\ % 7.  roadNet-TX       
7           & 19.6 & 197 & 10.2 & 303 & 10.3 & 297 & 61.8  & 321 & -    & -   & 26.8 \\ % 8.  belgium\_osm     
8           & 27.1 & 289 & 19.5 & 513 & 20.3 & 447 & 135.3 & 579 & -    & -   & 61.4 \\ % 9.  roadNet-CA       
9           & 33.1 & 263 & 15.2 & 423 & 18.2 & 385 & 76.1  & 457 & -    & -   & 47.0 \\ % 10. netherlands\_osm  
\hline
\end{tabular}
}
\end{table}
}
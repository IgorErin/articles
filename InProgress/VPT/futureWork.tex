\section{Future Work}

%We show that distillation is a promising way to optimize linear algebra-based programs, which makes it also applicable to optimize machine learning and graph processing procedures.

In the future, first, we should close a technical debt and make the distiller more stable to handle all the important cases: current implementation can not handle such important functions as matrix-matrix multiplication.
%Along with it, we should improve the input language to make it more user-friendly.
%The main challenge here is to find the balance between language expressivity and the practicality of distillation for it.
Having basic workflow implemented, we should explore how to utilize distillation in the best way for each particular platform. 
For example, which level of distillation is the best for our particular problem and set of functions?
Can we exploit more parallelism using distillation?
Can we efficiently exploit the tail-modulo-cons property of the distilled program?
What are the limitations of distillation: whether all important cases can be handled?

%When the language and the distiller are stable enough, we plan to implement a full-featured generic linear algebra library power enough to express basic graph analysis algorithms and to create and train neural networks.
%After that, a number of graph analysis algorithms and neural networks will be implemented and evaluated.

In addition to it, we plan to improve both FHW and Reduceron and compilers for them in order to make them mature enough to handle real-world examples.
The most relevant improvement here, for example, is the support for out-of-chip memory.

%Finally, a comprehensive evaluation of proposed solutions should be done using FPGA, not hardware simulators. The main challenge here is to utilize the resources of modern FPGA accelerators, such as HBM, to achieve the maximal performance of our solution.
@misc{yang2019graphblast,
    title={GraphBLAST: A High-Performance Linear Algebra-based Graph Framework on the GPU},
    author={Carl Yang and Aydin Buluc and John D. Owens},
    year={2019},
    eprint={1908.01407},
    archivePrefix={arXiv},
    primaryClass={cs.DC}
}

@article{Coimbra2021,
  doi = {10.1186/s40537-021-00443-9},
  url = {https://doi.org/10.1186/s40537-021-00443-9},
  year = {2021},
  month = apr,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {8},
  number = {1},
  author = {Miguel E. Coimbra and Alexandre P. Francisco and Lu{\'{\i}}s Veiga},
  title = {An analysis of the graph processing landscape},
  journal = {Journal of Big Data}
}

@INPROCEEDINGS{7761646,  author={Kepner, Jeremy and Aaltonen, Peter and Bader, David and Buluç, Aydin and Franchetti, Franz and Gilbert, John and Hutchison, Dylan and Kumar, Manoj and Lumsdaine, Andrew and Meyerhenke, Henning and McMillan, Scott and Yang, Carl and Owens, John D. and Zalewski, Marcin and Mattson, Timothy and Moreira, Jose},  booktitle={2016 IEEE High Performance Extreme Computing Conference (HPEC)},   title={Mathematical foundations of the GraphBLAS},   year={2016},  volume={},  number={},  pages={1-9},  doi={10.1109/HPEC.2016.7761646}}

@article{Huang2022TaskflowAL,
  title={Taskflow: A Lightweight Parallel and Heterogeneous Task Graph Computing System},
  author={Tsung-Wei Huang and Dian-Lun Lin and Chun-Xun Lin and Yibo Lin},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  year={2022},
  volume={33},
  pages={1303-1320}
}

@article{10.1145/2049662.2049663,
author = {Davis, Timothy A. and Hu, Yifan},
title = {The University of Florida Sparse Matrix Collection},
year = {2011},
issue_date = {November 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0098-3500},
url = {https://doi.org/10.1145/2049662.2049663},
doi = {10.1145/2049662.2049663},
abstract = {We describe the University of Florida Sparse Matrix Collection, a large and actively growing set of sparse matrices that arise in real applications. The Collection is widely used by the numerical linear algebra community for the development and performance evaluation of sparse matrix algorithms. It allows for robust and repeatable experiments: robust because performance results with artificially generated matrices can be misleading, and repeatable because matrices are curated and made publicly available in many formats. Its matrices cover a wide spectrum of domains, include those arising from problems with underlying 2D or 3D geometry (as structural engineering, computational fluid dynamics, model reduction, electromagnetics, semiconductor devices, thermodynamics, materials, acoustics, computer graphics/vision, robotics/kinematics, and other discretizations) and those that typically do not have such geometry (optimization, circuit simulation, economic and financial modeling, theoretical and quantum chemistry, chemical process simulation, mathematics and statistics, power networks, and other networks and graphs). We provide software for accessing and managing the Collection, from MATLAB™, Mathematica™, Fortran, and C, as well as an online search capability. Graph visualization of the matrices is provided, and a new multilevel coarsening scheme is proposed to facilitate this task.},
journal = {ACM Trans. Math. Softw.},
month = {dec},
articleno = {1},
numpages = {25},
keywords = {performance evaluation, Graph drawing, sparse matrices, multilevel algorithms}
}

@article{10.1145/3322125,
author = {Davis, Timothy A.},
title = {Algorithm 1000: SuiteSparse:GraphBLAS: Graph Algorithms in the Language of Sparse Linear Algebra},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0098-3500},
url = {https://doi.org/10.1145/3322125},
doi = {10.1145/3322125},
journal = {ACM Trans. Math. Softw.},
month = dec,
articleno = {44},
numpages = {25},
keywords = {sparse matrices, GraphBLAS, Graph algorithms}
}

@INPROCEEDINGS{7529957,
  author={Zhang, Peter and Zalewski, Marcin and Lumsdaine, Andrew and Misurda, Samantha and McMillan, Scott},
  booktitle={2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={GBTL-CUDA: Graph Algorithms and Primitives for GPUs}, 
  year={2016},
  volume={},
  number={},
  pages={912-920},
  doi={10.1109/IPDPSW.2016.185}}

@inproceedings{10.1145/2600212.2600227,
author = {Khorasani, Farzad and Vora, Keval and Gupta, Rajiv and Bhuyan, Laxmi N.},
title = {CuSha: Vertex-Centric Graph Processing on GPUs},
year = {2014},
isbn = {9781450327497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2600212.2600227},
doi = {10.1145/2600212.2600227},
abstract = {Vertex-centric graph processing is employed by many popular algorithms (e.g., PageRank) due to its simplicity and efficient use of asynchronous parallelism. The high compute power provided by SIMT architecture presents an opportunity for accelerating these algorithms using GPUs. Prior works of graph processing on a GPU employ Compressed Sparse Row (CSR) form for its space-efficiency; however, CSR suffers from irregular memory accesses and GPU underutilization that limit its performance. In this paper, we present CuSha, a CUDA-based graph processing framework that overcomes the above obstacle via use of two novel graph representations: G-Shards and Concatenated Windows (CW). G-Shards uses a concept recently introduced for non-GPU systems that organizes a graph into autonomous sets of ordered edges called shards. CuSha's mapping of GPU hardware resources on to shards allows fully coalesced memory accesses. CW is a novel representation that enhances the use of shards to achieve higher GPU utilization for processing sparse graphs. Finally, CuSha fully utilizes the GPU power by processing multiple shards in parallel on GPU's streaming multiprocessors. For ease of programming, CuSha allows the user to define the vertex-centric computation and plug it into its framework for parallel processing of large graphs. Our experiments show that CuSha provides significant speedups over the state-of-the-art CSR-based virtual warp-centric method for processing graphs on GPUs.},
booktitle = {Proceedings of the 23rd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {239–252},
numpages = {14},
keywords = {graph representation, coalesced memory accesses, concatenated windows, g-shards, gpu},
location = {Vancouver, BC, Canada},
series = {HPDC '14}
}

@INPROCEEDINGS{7967137,  author={Pan, Yuechao and Wang, Yangzihao and Wu, Yuduo and Yang, Carl and Owens, John D.},  booktitle={2017 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},   title={Multi-GPU Graph Analytics},   year={2017},  volume={},  number={},  pages={479-490},  doi={10.1109/IPDPS.2017.117}}
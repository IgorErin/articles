\section{Introduction}

Scalable high-performance graph analysis is an actual challenge. There is a big number of ways to attach this challenge~\cite{Coimbra2021}.
And one of te promising ways is To utilize general purpose graphic processing units (GPGPU-s) for graph analysis.
Existing solutions demonstrate good performance.
Scalable. 
But existing solutions provide a very low level API for graph algorithms construction.
As a result, Verbosity, so on

One of promising ways to high performance graph analysis is a GraphBLAS API\footnote{GraphBLAS home page: \url{https://graphblas.org/}. Accass date: 07.01.2022.}~\cite{!!!} provides a linear algebra based building blocks~\cite{7761646} to create graph analysis algorithms.
The idea of GraphBLAS is based on is well-known fact that linear algebra operations can be efficiently implemented on parallel hardware.
Within it, a graph can be natively represented using matrices: adjacency matrix, incidence matrix, etc.
But real data often sparse, thus underlying matrices and vectors also sparse, and classical data structures and algorithms became inefficient. 
This fact leads to sparse linear algebra.
Generic sparse linear algebra.
SuiteSparse:GraphBLAS\footnote{\url{!!!}}~\cite{!!!}.

Though such well-known libraries as cuSparse show that sparse linear algebra operations can be efficiently implemented for GPGPU-s, it is not so trivial to implement GraphBLAS on GPGPU. 
First of all, it requires \textit{generic} sparse linear algebra, thus it is impossible jus tu reuse existing libraries which almost specified for operations over floats and doubles.
The second problem is specific optimizations, such as maskings fusion, which can not be natively implemented on top of existing kernels.
GraphBLAS on GPGPU.
GraphBLAST:~\cite{yang2019graphblast}, GBTL~\cite{!!!}, !!!.
But these solutions are not portable (because thea are based on Nvidia Cuda stack).
Moreover, scalability problem is not solved: all these solutions support only single-GPU, not multi-GPU computations.

To provide portable multi-GPU implementation of GraphBLAS API we developed a \textit{SPLA}\footnote{SPLA home page: \url{https://jetbrains-research.github.io/spla/}.} library.
Contribution
\begin{itemize}
    \item Design
    \item Implemented
    \item Evaluation
\end{itemize} 
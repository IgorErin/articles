@incollection{TensorFlowXLA,
  title = {XLA: Optimizing Compiler for Machine Learning},
  url = {https://www.tensorflow.org/xla?hl=en},
  urldate = {2022-06-07}
}


@ARTICLE{GoogleTPU,  author={S. {Cass}},  journal={IEEE Spectrum},   title={Taking AI to the edge: Google's TPU now comes in a maker-friendly package},   year={2019},  volume={56},  number={5},  pages={16-17},  doi={10.1109/MSPEC.2019.8701189}}

@inproceedings{barefoot,
  title={Netchain: Scale-free sub-rtt coordination},
  author={Jin, Xin and Li, Xiaozhou and Zhang, Haoyu and Foster, Nate and Lee, Jeongkeun and Soul{\'e}, Robert and Kim, Changhoon and Stoica, Ion},
  booktitle={15th $\{$USENIX$\}$ Symposium on Networked Systems Design and Implementation ($\{$NSDI$\}$ 18)},
  pages={35--49},
  year={2018}
}

@inproceedings{redgrave2018pixel,
  title={Pixel Visual Core: Google’s Fully Programmable Image Vision and AI Processor For Mobile Devices},
  author={Redgrave, Jason and Meixner, Albert and Goulding-Hotta, Nathan and Vasilyev, Artem and Shacham, Ofer},
  booktitle={Proc. IEEE Hot Chips Symp.(HCS)},
  pages={1--18},
  year={2018}
}
@article{halide,
author = {Ragan-Kelley, Jonathan and Barnes, Connelly and Adams, Andrew and Paris, Sylvain and Durand, Fr\'{e}do and Amarasinghe, Saman},
title = {Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines},
year = {2013},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/2499370.2462176},
doi = {10.1145/2499370.2462176},
abstract = {Image processing pipelines combine the challenges of stencil computations and stream programs. They are composed of large graphs of different stencil stages, as well as complex reductions, and stages with global or data-dependent access patterns. Because of their complex structure, the performance difference between a naive implementation of a pipeline and an optimized one is often an order of magnitude. Efficient implementations require optimization of both parallelism and locality, but due to the nature of stencils, there is a fundamental tension between parallelism, locality, and introducing redundant recomputation of shared values.We present a systematic model of the tradeoff space fundamental to stencil pipelines, a schedule representation which describes concrete points in this space for each stage in an image processing pipeline, and an optimizing compiler for the Halide image processing language that synthesizes high performance implementations from a Halide algorithm and a schedule. Combining this compiler with stochastic search over the space of schedules enables terse, composable programs to achieve state-of-the-art performance on a wide range of real image processing pipelines, and across different hardware architectures, including multicores with SIMD, and heterogeneous CPU+GPU execution. From simple Halide programs written in a few hours, we demonstrate performance up to 5x faster than hand-tuned C, intrinsics, and CUDA implementations optimized by experts over weeks or months, for image processing applications beyond the reach of past automatic compilers.},
journal = {SIGPLAN Not.},
month = jun,
pages = {519–530},
numpages = {12},
keywords = {gpu, image processing, locality, autotuning, optimization, parallelism, redundant computation, vectorization, compiler, domain specific language}
}

@inproceedings{10.1145/2491956.2462176,
author = {Ragan-Kelley, Jonathan and Barnes, Connelly and Adams, Andrew and Paris, Sylvain and Durand, Fr\'{e}do and Amarasinghe, Saman},
title = {Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines},
year = {2013},
isbn = {9781450320146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491956.2462176},
doi = {10.1145/2491956.2462176},
abstract = {Image processing pipelines combine the challenges of stencil computations and stream programs. They are composed of large graphs of different stencil stages, as well as complex reductions, and stages with global or data-dependent access patterns. Because of their complex structure, the performance difference between a naive implementation of a pipeline and an optimized one is often an order of magnitude. Efficient implementations require optimization of both parallelism and locality, but due to the nature of stencils, there is a fundamental tension between parallelism, locality, and introducing redundant recomputation of shared values.We present a systematic model of the tradeoff space fundamental to stencil pipelines, a schedule representation which describes concrete points in this space for each stage in an image processing pipeline, and an optimizing compiler for the Halide image processing language that synthesizes high performance implementations from a Halide algorithm and a schedule. Combining this compiler with stochastic search over the space of schedules enables terse, composable programs to achieve state-of-the-art performance on a wide range of real image processing pipelines, and across different hardware architectures, including multicores with SIMD, and heterogeneous CPU+GPU execution. From simple Halide programs written in a few hours, we demonstrate performance up to 5x faster than hand-tuned C, intrinsics, and CUDA implementations optimized by experts over weeks or months, for image processing applications beyond the reach of past automatic compilers.},
booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {519–530},
numpages = {12},
keywords = {autotuning, gpu, optimization, parallelism, vectorization, compiler, image processing, redundant computation, domain specific language, locality},
location = {Seattle, Washington, USA},
series = {PLDI '13}
}



@INPROCEEDINGS{SuiteSparse,  author={T. A. {Davis}},  booktitle={2018 IEEE High Performance extreme Computing Conference (HPEC)},   title={Graph algorithms via SuiteSparse: GraphBLAS: triangle counting and K-truss},   year={2018},  volume={},  number={},  pages={1-6},  doi={10.1109/HPEC.2018.8547538}}

@INPROCEEDINGS{redis,  author={P. {Cailliau} and T. {Davis} and V. {Gadepally} and J. {Kepner} and R. {Lipman} and J. {Lovitz} and K. {Ouaknine}},  booktitle={2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},   title={RedisGraph --- GraphBLAS Enabled Graph Database},   year={2019},  volume={},  number={},  pages={285-286},  doi={10.1109/IPDPSW.2019.00054}}

@article{graph2,
title = "The anatomy of a large-scale hypertextual Web search engine",
journal = "Computer Networks and ISDN Systems",
volume = "30",
number = "1",
pages = "107 - 117",
year = "1998",
note = "Proceedings of the Seventh International World Wide Web Conference",
issn = "0169-7552",
doi = "https://doi.org/10.1016/S0169-7552(98)00110-X",
url = "http://www.sciencedirect.com/science/article/pii/S016975529800110X",
author = "Sergey Brin and Lawrence Page",
keywords = "World Wide Web, Search engines, Information retrieval, PageRank, Google"
}
@INPROCEEDINGS{graph1,  author={M. {Besta} and F. {Marending} and E. {Solomonik} and T. {Hoefler}},  booktitle={2017 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},   title={SlimSell: A Vectorizable Graph Representation for Breadth-First Search},   year={2017},  volume={},  number={},  pages={32-41},  doi={10.1109/IPDPS.2017.93}}

@article{amazon,
author = {Linden, Greg and Smith, Brent and York, Jeremy},
title = {Amazon.Com Recommendations: Item-to-Item Collaborative Filtering},
year = {2003},
issue_date = {January 2003},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {7},
number = {1},
issn = {1089-7801},
url = {https://doi.org/10.1109/MIC.2003.1167344},
doi = {10.1109/MIC.2003.1167344},
abstract = {By comparing similar items rather than similar customers, item-to-item collaborative filtering scales to very large data sets and produces high-quality recommendations.},
journal = {IEEE Internet Computing},
month = jan,
pages = {76–80},
numpages = {5}
}

@misc{gupta2020architectural,
      title={The Architectural Implications of Facebook's DNN-based Personalized Recommendation}, 
      author={Udit Gupta and Carole-Jean Wu and Xiaodong Wang and Maxim Naumov and Brandon Reagen and David Brooks and Bradford Cottel and Kim Hazelwood and Bill Jia and Hsien-Hsin S. Lee and Andrey Malevich and Dheevatsa Mudigere and Mikhail Smelyanskiy and Liang Xiong and Xuan Zhang},
      year={2020},
      eprint={1906.03109},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@book{GAILLA,
author = {Kepner, Jeremy and Gilbert, John},
title = {Graph Algorithms in the Language of Linear Algebra},
year = {2011},
isbn = {0898719909},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {Graphs are among the most important abstract data types in computer science, and the algorithms that operate on them are critical to modern life. Graphs have been shown to be powerful tools for modeling complex problems because of their simplicity and generality. Graph algorithms are one of the pillars of mathematics, informing research in such diverse areas as combinatorial optimization, complexity theory, and topology. Algorithms on graphs are applied in many ways in today s world - from Web rankings to metabolic networks, from finite element meshes to semantic graphs. The current exponential growth in graph data has forced a shift to parallel computing for executing graph algorithms. Implementing parallel graph algorithms and achieving good parallel performance have proven difficult. This book addresses these challenges by exploiting the well-known duality between a canonical representation of graphs as abstract collections of vertices and edges and a sparse adjacency matrix representation. This linear algebraic approach is widely accessible to scientists and engineers who may not be formally trained in computer science. The authors show how to leverage existing parallel matrix computation techniques and the large amount of software infrastructure that exists for these computations to implement efficient and scalable parallel graph algorithms. The benefits of this approach are reduced algorithmic complexity, ease of implementation, and improved performance. Graph Algorithms in the Language of Linear Algebra is the first book to cover graph algorithms accessible to engineers and scientists not trained in computer science but having a strong linear algebra background, enabling them to quickly understand and apply graph algorithms. It also covers array-based graph algorithms, showing readers how to express canonical graph algorithms using a highly elegant and efficient array notation and how to tap into the large range of tools and techniques that have been built for matrices and tensors; parallel array-based algorithms, demonstrating with examples how to easily implement parallel graph algorithms using array-based approaches, which enables readers to address much larger graph problems; and array-based theory for analyzing graphs, providing a template for using array-based constructs to develop new theoretical approaches for graph analysis. Audience: This book is suitable as the primary text for a class on linear algebraic graph algorithms and as either the primary or supplemental text for a class on graph algorithms for engineers and scientists without training in computer science. Contents: List of Figures; List of Tables; List of Algorithms; Preface; Acknowledgments; Part I: Algorithms: Chapter 1: Graphs and Matrices; Chapter 2: Linear Algebraic Notation and Definitions; Chapter 3: Connected Components and Minimum Paths; Chapter 4: Some Graph Algorithms in an Array-Based Language; Chapter 5: Fundamental Graph Algorithms; Chapter 6: Complex Graph Algorithms; Chapter 7: Multilinear Algebra for Analyzing Data with Multiple Linkages; Chapter 8: Subgraph Detection; Part II: Data: Chapter 9: Kronecker Graphs; Chapter 10: The Kronecker Theory of Power Law Graphs; Chapter 11: Visualizing Large Kronecker Graphs; Part III: Computation: Chapter 12: Large-Scale Network Analysis; Chapter 13: Implementing Sparse Matrices for Graph Algorithms; Chapter 14: New Ideas in Sparse Matrix-Matrix Multiplication; Chapter 15: Parallel Mapping of Sparse Computations; Chapter 16: Fundamental Questions in the Analysis of Large Graphs; Index.}
}

@article{buluc2017graphblas,
  title={The GraphBLAS C API Specification},
  author={Buluc, Aydin and Mattson, Timothy and McMillan, Scott and Moreira, Jose and Yang, Carl},
  journal={GraphBLAS. org, Tech. Rep.},
  year={2017}
}

@misc{yang2020graphblast,
      title={GraphBLAST: A High-Performance Linear Algebra-based Graph Framework on the GPU}, 
      author={Carl Yang and Aydin Buluc and John D. Owens},
      year={2020},
      eprint={1908.01407},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}
@article{KernelFusion,
   title={Optimizing CUDA code by kernel fusion: application on BLAS},
   volume={71},
   ISSN={1573-0484},
   url={http://dx.doi.org/10.1007/s11227-015-1483-z},
   DOI={10.1007/s11227-015-1483-z},
   number={10},
   journal={The Journal of Supercomputing},
   publisher={Springer Science and Business Media LLC},
   author={Filipovič, Jiří and Madzin, Matúš and Fousek, Jan and Matyska, Luděk},
   year={2015},
   month={Jul},
   pages={3934–3957}
}

@inproceedings{10.1145/3062341.3062354,
author = {Henriksen, Troels and Serup, Niels G. W. and Elsman, Martin and Henglein, Fritz and Oancea, Cosmin E.},
title = {Futhark: Purely Functional GPU-Programming with Nested Parallelism and in-Place Array Updates},
year = {2017},
isbn = {9781450349888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3062341.3062354},
doi = {10.1145/3062341.3062354},
abstract = { Futhark is a purely functional data-parallel array language that offers a machine-neutral programming model and an optimising compiler that generates OpenCL code for GPUs.  This paper presents the design and implementation of three key features of Futhark that seek a suitable middle ground with imperative approaches.  First, in order to express efficient code inside the parallel constructs, we introduce a simple type system for in-place updates that ensures referential transparency and supports equational reasoning.  Second, we furnish Futhark with parallel operators capable of expressing efficient strength-reduced code, along with their fusion rules.  Third, we present a flattening transformation aimed at enhancing the degree of parallelism that (i) builds on loop interchange and distribution but uses higher-order reasoning rather than array-dependence analysis, and (ii) still allows further locality-of-reference optimisations. Finally, an evaluation on 16 benchmarks demonstrates the impact of the language and compiler features and shows application-level performance competitive with hand-written GPU code. },
booktitle = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {556–571},
numpages = {16},
keywords = {compilers, functional language, parallel, GPGPU},
location = {Barcelona, Spain},
series = {PLDI 2017}
}

@article{Futhark,
author = {Henriksen, Troels and Serup, Niels G. W. and Elsman, Martin and Henglein, Fritz and Oancea, Cosmin E.},
title = {Futhark: Purely Functional GPU-Programming with Nested Parallelism and in-Place Array Updates},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/3140587.3062354},
doi = {10.1145/3140587.3062354},
abstract = { Futhark is a purely functional data-parallel array language that offers a machine-neutral programming model and an optimising compiler that generates OpenCL code for GPUs.  This paper presents the design and implementation of three key features of Futhark that seek a suitable middle ground with imperative approaches.  First, in order to express efficient code inside the parallel constructs, we introduce a simple type system for in-place updates that ensures referential transparency and supports equational reasoning.  Second, we furnish Futhark with parallel operators capable of expressing efficient strength-reduced code, along with their fusion rules.  Third, we present a flattening transformation aimed at enhancing the degree of parallelism that (i) builds on loop interchange and distribution but uses higher-order reasoning rather than array-dependence analysis, and (ii) still allows further locality-of-reference optimisations. Finally, an evaluation on 16 benchmarks demonstrates the impact of the language and compiler features and shows application-level performance competitive with hand-written GPU code. },
journal = {SIGPLAN Not.},
month = jun,
pages = {556–571},
numpages = {16},
keywords = {parallel, functional language, compilers, GPGPU}
}



@inproceedings{CUDADMA,
author = {Bauer, Michael and Cook, Henry and Khailany, Brucek},
title = {CudaDMA: Optimizing GPU Memory Bandwidth via Warp Specialization},
year = {2011},
isbn = {9781450307710},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2063384.2063400},
doi = {10.1145/2063384.2063400},
abstract = {As the computational power of GPUs continues to scale with Moore's Law, an increasing number of applications are becoming limited by memory bandwidth. We propose an approach for programming GPUs with tightly-coupled specialized DMA warps for performing memory transfers between on-chip and off-chip memories. Separate DMA warps improve memory bandwidth utilization by better exploiting available memory-level parallelism and by leveraging efficient inter-warp producer-consumer synchronization mechanisms. DMA warps also improve programmer productivity by decoupling the need for thread array shapes to match data layout. To illustrate the benefits of this approach, we present an extensible API, CudaDMA, that encapsulates synchronization and common sequential and strided data transfer patterns. Using CudaDMA, we demonstrate speedup of up to 1.37x on representative synthetic microbenchmarks, and 1.15x-3.2x on several kernels from scientific applications written in CUDA running on NVIDIA Fermi GPUs.},
booktitle = {Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {12},
numpages = {11},
location = {Seattle, Washington},
series = {SC '11}
}

@article{Song_2016,
   title={Novel graph processor architecture, prototype system, and results},
   ISBN={9781509035250},
   url={http://dx.doi.org/10.1109/HPEC.2016.7761635},
   DOI={10.1109/hpec.2016.7761635},
   journal={2016 IEEE High Performance Extreme Computing Conference (HPEC)},
   publisher={IEEE},
   author={Song, William S. and Gleyzer, Vitaliy and Lomakin, Alexei and Kepner, Jeremy},
   year={2016},
   month={Sep}
}

@misc{leskovec2016snap,
      title={SNAP: A General Purpose Network Analysis and Graph Mining Library}, 
      author={Jure Leskovec and Rok Sosic},
      year={2016},
      eprint={1606.07550},
      archivePrefix={arXiv},
      primaryClass={cs.SI}
}

@article{Florida,
author = {Davis, Timothy A. and Hu, Yifan},
title = {The University of Florida Sparse Matrix Collection},
year = {2011},
issue_date = {November 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0098-3500},
url = {https://doi.org/10.1145/2049662.2049663},
doi = {10.1145/2049662.2049663},
abstract = {We describe the University of Florida Sparse Matrix Collection, a large and actively growing set of sparse matrices that arise in real applications. The Collection is widely used by the numerical linear algebra community for the development and performance evaluation of sparse matrix algorithms. It allows for robust and repeatable experiments: robust because performance results with artificially generated matrices can be misleading, and repeatable because matrices are curated and made publicly available in many formats. Its matrices cover a wide spectrum of domains, include those arising from problems with underlying 2D or 3D geometry (as structural engineering, computational fluid dynamics, model reduction, electromagnetics, semiconductor devices, thermodynamics, materials, acoustics, computer graphics/vision, robotics/kinematics, and other discretizations) and those that typically do not have such geometry (optimization, circuit simulation, economic and financial modeling, theoretical and quantum chemistry, chemical process simulation, mathematics and statistics, power networks, and other networks and graphs). We provide software for accessing and managing the Collection, from MATLAB™, Mathematica™, Fortran, and C, as well as an online search capability. Graph visualization of the matrices is provided, and a new multilevel coarsening scheme is proposed to facilitate this task.},
journal = {ACM Trans. Math. Softw.},
month = dec,
articleno = {1},
numpages = {25},
keywords = {multilevel algorithms, Graph drawing, sparse matrices, performance evaluation}
}

 @inproceedings{zhang2020sparch,
    title     = {SpArch: Efficient Architecture for Sparse Matrix Multiplication},
    author    = {Zhang, Zhekai and Wang, Hanrui and Han, Song and Dally, William J.},
    booktitle = {26th IEEE International Symposium on High Performance Computer Architecture (HPCA)},
    year      = {2020}
} 

@inproceedings{Systolic,
author = {He, Xin and Pal, Subhankar and Amarnath, Aporva and Feng, Siying and Park, Dong-Hyeon and Rovinski, Austin and Ye, Haojie and Chen, Yuhan and Dreslinski, Ronald and Mudge, Trevor},
title = {Sparse-TPU: Adapting Systolic Arrays for Sparse Matrices},
year = {2020},
isbn = {9781450379830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3392717.3392751},
doi = {10.1145/3392717.3392751},
abstract = {While systolic arrays are widely used for dense-matrix operations, they are seldom used for sparse-matrix operations. In this paper, we show how a systolic array of Multiply-and-Accumulate (MAC) units, similar to Google's Tensor Processing Unit (TPU), can be adapted to efficiently handle sparse matrices. TPU-like accelerators are built upon a 2D array of MAC units and have demonstrated high throughput and efficiency for dense matrix multiplication, which is a key kernel in machine learning algorithms and is the target of the TPU. In this work, we employ a co-designed approach of first developing a packing technique to condense a sparse matrix and then propose a systolic array based system, Sparse-TPU, abbreviated to STPU, to accommodate the matrix computations for the packed denser matrix counterparts. To demonstrate the efficacy of our co-designed approach, we evaluate sparse matrix-vector multiplication on a broad set of synthetic and real-world sparse matrices. Experimental results show that STPU delivers 16.08X higher performance while consuming 4.39X and 19.79X lower energy for integer (int8) and floating point (float32) implementations, respectively, over a TPU baseline. Meanwhile, STPU has 12.93% area overhead and an average of 4.14% increase in dynamic energy over the TPU baseline for the float32 implementation.},
booktitle = {Proceedings of the 34th ACM International Conference on Supercomputing},
articleno = {19},
numpages = {12},
keywords = {sparse matrix condensing, hardware-software codesign, hardware accelerators, application-specific hardware, systolic array, sparse matrix processing},
location = {Barcelona, Spain},
series = {ICS '20}
}

@misc{CPU-FPGA,
      title={Synergistic CPU-FPGA Acceleration of Sparse Linear Algebra}, 
      author={Mohammadreza Soltaniyeh and Richard P. Martin and Santosh Nagarakatte},
      year={2020},
      eprint={2004.13907},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@misc{compBio,
      title={Distributed Many-to-Many Protein Sequence Alignment using Sparse Matrices}, 
      author={Oguz Selvitopi and Saliya Ekanayake and Giulia Guidi and Georgios Pavlopoulos and Ariful Azad and Aydin Buluc},
      year={2020},
      eprint={2009.14467},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@article{Kepner_2017,
   title={Enabling massive deep neural networks with the GraphBLAS},
   ISBN={9781538634721},
   url={http://dx.doi.org/10.1109/HPEC.2017.8091098},
   DOI={10.1109/hpec.2017.8091098},
   journal={2017 IEEE High Performance Extreme Computing Conference (HPEC)},
   publisher={IEEE},
   author={Kepner, Jeremy and Kumar, Manoj and Moreira, Jose and Pattnaik, Pratap and Serrano, Mauricio and Tufo, Henry},
   year={2017},
   month={Sep}
}

@book{jones,
author = {Jones, Neil D. and Gomard, Carsten K. and Sestoft, Peter},
title = {Partial Evaluation and Automatic Program Generation},
year = {1993},
isbn = {0130202495},
publisher = {Prentice-Hall, Inc.},
address = {USA}
}

@article{10.1145/1291220.1291199,
author = {Coutts, Duncan and Leshchinskiy, Roman and Stewart, Don},
title = {Stream Fusion: From Lists to Streams to Nothing at All},
year = {2007},
issue_date = {September 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/1291220.1291199},
doi = {10.1145/1291220.1291199},
abstract = {This paper presents an automatic deforestation system, stream fusion, based on equational transformations, that fuses a wider range of functions than existing short-cut fusion systems. In particular, stream fusion is able to fuse zips, left folds and functions over nested lists, including list comprehensions. A distinguishing feature of the framework is its simplicity: by transforming list functions to expose their structure, intermediate values are eliminated by general purpose compiler optimisations.We have reimplemented the Haskell standard List library on top of our framework, providing stream fusion for Haskell lists. By allowing a wider range of functions to fuse, we see an increase in the number of occurrences of fusion in typical Haskell programs. We present benchmarks documenting time and space improvements.},
journal = {SIGPLAN Not.},
month = oct,
pages = {315–326},
numpages = {12},
keywords = {program transformation, program fusion, program optimisation, deforestation, functional programming}
}

@inproceedings{fusion,
author = {Coutts, Duncan and Leshchinskiy, Roman and Stewart, Don},
title = {Stream Fusion: From Lists to Streams to Nothing at All},
year = {2007},
isbn = {9781595938152},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291151.1291199},
doi = {10.1145/1291151.1291199},
abstract = {This paper presents an automatic deforestation system, stream fusion, based on equational transformations, that fuses a wider range of functions than existing short-cut fusion systems. In particular, stream fusion is able to fuse zips, left folds and functions over nested lists, including list comprehensions. A distinguishing feature of the framework is its simplicity: by transforming list functions to expose their structure, intermediate values are eliminated by general purpose compiler optimisations.We have reimplemented the Haskell standard List library on top of our framework, providing stream fusion for Haskell lists. By allowing a wider range of functions to fuse, we see an increase in the number of occurrences of fusion in typical Haskell programs. We present benchmarks documenting time and space improvements.},
booktitle = {Proceedings of the 12th ACM SIGPLAN International Conference on Functional Programming},
pages = {315–326},
numpages = {12},
keywords = {program transformation, program optimisation, deforestation, program fusion, functional programming},
location = {Freiburg, Germany},
series = {ICFP '07}
}

@article{SMASH,
   title={SMASH},
   ISBN={9781450369381},
   url={http://dx.doi.org/10.1145/3352460.3358286},
   DOI={10.1145/3352460.3358286},
   journal={Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture},
   publisher={ACM},
   author={Kanellopoulos, Konstantinos and Vijaykumar, Nandita and Giannoula, Christina and Azizi, Roknoddin and Koppula, Skanda and Ghiasi, Nika Mansouri and Shahroodi, Taha and Luna, Juan Gomez and Mutlu, Onur},
   year={2019},
   month={Oct}
}

@article{sakr2020future,
  title={The Future is Big Graphs! A Community View on Graph Processing Systems},
  author={Sakr, Sherif and Bonifati, Angela and Voigt, Hannes and Iosup, Alexandru and Ammar, Khaled and Angles, Renzo and Aref, Walid and Arenas, Marcelo and Besta, Maciej and Boncz, Peter A and others},
  journal={arXiv preprint arXiv:2012.06171},
  year={2020}
}

@Inbook{TCEToolset,
	author="J{\"a}{\"a}skel{\"a}inen, Pekka and Viitanen, Timo and Takala, Jarmo and Berg, Heikki",
	editor="Hussain, Waqar and Nurmi, Jari and Isoaho, Jouni and Garzia, Fabio",
	title="HW/SW Co-design Toolset for Customization of Exposed Datapath Processors",
	bookTitle="Computing Platforms for Software-Defined Radio",
	year="2017",
	publisher="Springer International Publishing",
	pages="147--164",
	isbn="978-3-319-49679-5",
	doi="10.1007/978-3-319-49679-5_8",
	url="https://doi.org/10.1007/978-3-319-49679-5_8"
}

@inproceedings{Edwards2019FHWP,
  title={FHW Project : High-Level Hardware Synthesis from Haskell Programs},
  author={S. Edwards and Martha A. Kim and Richard Townsend and Kuangya Zhai and L. Lairmore},
  year={2019}
}


@INPROCEEDINGS{SparseDNN,  author={Davis, Timothy A. and Aznaveh, Mohsen and Kolodziej, Scott},  booktitle={2019 IEEE High Performance Extreme Computing Conference (HPEC)},   title={Write Quick, Run Fast: Sparse Deep Neural Network in 20 Minutes of Development Time via SuiteSparse:GraphBLAS},   year={2019},  volume={},  number={},  pages={1-6},  doi={10.1109/HPEC.2019.8916550}}

@incollection{SuiteSparseOnly,
  title = {Algorithm 9xx: SuiteSparse:GraphBLAS: graph algorithms in
the language of sparse linear algebra},
  url = {https://people.engr.tamu.edu/davis/publications_files/toms_graphblas.pdf},
  author={Timothy A. Davis, Texas A\&M University, USA},
  urldate = {2022-06-07}
}


@article{WADLER1990231,
title = {Deforestation: transforming programs to eliminate trees},
journal = {Theoretical Computer Science},
volume = {73},
number = {2},
pages = {231-248},
year = {1990},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(90)90147-A},
url = {https://www.sciencedirect.com/science/article/pii/030439759090147A},
author = {Philip Wadler},
abstract = {An algorithm that transforms programs to eliminate intermediate trees is presented. The algorithm applies to any term containing only functions with definitions in a given syntactic form, and is suitable for incorporation in an optimizing compiler.}
}

@article{supercompilation,
author = {Sørensen, Morten and Glück, R. and Jones, Neil},
year = {1996},
month = {11},
pages = {811 - 838},
title = {A positive supercompiler},
volume = {6},
journal = {Journal of Functional Programming},
doi = {10.1017/S0956796800002008}
}

@inproceedings{distillation,
author = {Hamilton, Geoff},
year = {2009},
month = {06},
pages = {151-164},
title = {Extracting the Essence of Distillation},
isbn = {978-3-642-11485-4},
doi = {10.1007/978-3-642-11486-1_13}
}

@INPROCEEDINGS{qtree,  author={I. {Simecek}},  booktitle={2009 11th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing},   title={Sparse Matrix Computations Using the Quadtree Storage Format},   year={2009},  volume={},  number={},  pages={168-173},  doi={10.1109/SYNASC.2009.55}}


@article{hosc,
author = {Klyuchnikov, Ilya},
year = {2010},
month = {01},
pages = {},
title = {Supercompiler HOSC 1.5: homeomorphic embedding and generalization in a higher-order setting}
}

@inproceedings{funcHLS,
  title={Compiling Irregular Software to Specialized Hardware},
  author={Richard Townsend},
  year={2019}
}

@InProceedings{stagedLinAlg,
  author =	{Amir Shaikhha and Lionel Parreaux},
  title =	{{Finally, a Polymorphic Linear Algebra Language (Pearl)}},
  booktitle =	{33rd European Conference on Object-Oriented Programming (ECOOP 2019)},
  pages =	{25:1--25:29},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-111-5},
  ISSN =	{1868-8969},
  year =	{2019},
  volume =	{134},
  editor =	{Alastair F. Donaldson},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{http://drops.dagstuhl.de/opus/volltexte/2019/10817},
  URN =		{urn:nbn:de:0030-drops-108172},
  doi =		{10.4230/LIPIcs.ECOOP.2019.25},
  annote =	{Keywords: Linear Algebra, Domain-Specific Languages, Tagless Final, Polymorphic Embedding, Object Algebra, Multi-Stage Programming, Graph Processing, Probabili}
}

@article{StreamFus,
  author    = {Oleg Kiselyov and
               Aggelos Biboudis and
               Nick Palladinos and
               Yannis Smaragdakis},
  title     = {Stream Fusion, to Completeness},
  journal   = {CoRR},
  volume    = {abs/1612.06668},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.06668},
  eprinttype = {arXiv},
  eprint    = {1612.06668},
  timestamp = {Mon, 13 Aug 2018 16:47:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KiselyovBPS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{GRIN,
author = {Podlovics, Peter and Hruska, Csaba and Pénzes, Andor},
year = {2021},
month = {02},
pages = {},
title = {A Modern Look at GRIN, an Optimizing Functional Language Back End},
journal = {Acta Cybernetica},
doi = {10.14232/actacyb.282969}
}

@incollection{matrix-rep,
  author = {Aleksei Tiurin},
  title = {Quad tree matrx representation utilities},
  url = {https://github.com/Tiltedprogrammer/MatrixConverter},
  year = {2022}, 
  urldate = {2022-06-07}
}

@inproceedings{lambda-lift,
author = {Johnsson, Thomas},
title = {Lambda Lifting: Transforming Programs to Recursive Equations},
year = {1985},
isbn = {3387159754},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Proc. of a Conference on Functional Programming Languages and Computer Architecture},
pages = {190–203},
numpages = {14},
location = {Nancy, France}
}

@incollection{grin-rep,
  author = {Aleksei Tiurin},
  title = {Translator from \texttt{.pot} to \texttt{.grin}},
  url = {https://github.com/Tiltedprogrammer/SparseLinAlgHardware/tree/master/poitin-grin-frontend},
  year = {2022}, 
  urldate = {2022-06-07}
}


@inproceedings{ssacps,
author = {Kelsey, Richard A.},
title = {A Correspondence between Continuation Passing Style and Static Single Assignment Form},
year = {1995},
isbn = {0897917545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/202529.202532},
doi = {10.1145/202529.202532},
abstract = {We define syntactic transformations that convert continuation passing style (CPS) programs into static single assignment form (SSA) and vice versa. Some CPS programs cannot be converted to SSA, but these are not produced by the usual CPS transformation. The CPS→SSA transformation is especially helpful for compiling functional programs. Many optimizations that normally require flow analysis can be performed directly on functional CPS programs by viewing them as SSA programs. We also present a simple program transformation that merges CPS procedures together and by doing so greatly increases the scope of the SSA flow information. This transformation is useful for analyzing loops expressed as recursive procedures.},
booktitle = {Papers from the 1995 ACM SIGPLAN Workshop on Intermediate Representations},
pages = {13–22},
numpages = {10},
location = {San Francisco, California, USA},
series = {IR '95}
}

@inproceedings{typeyourmatricesforgreatgood,
author = {Santos, Armando and Oliveira, Jos\'{e} N.},
title = {Type Your Matrices for Great Good: A Haskell Library of Typed Matrices and Applications (Functional Pearl)},
year = {2020},
isbn = {9781450380508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406088.3409019},
doi = {10.1145/3406088.3409019},
abstract = {We study a simple inductive data type for representing correct-by-construction matrices. Despite its simplicity, it can be used to implement matrix-manipulation algorithms efficiently and safely, performing in some cases faster than existing alternatives even though the algorithms are written in a direct and purely functional style. A rich collection of laws makes it possible to derive and optimise these algorithms using equational reasoning, avoiding the notorious off-by-one indexing errors when fiddling with matrix dimensions. We demonstrate the usefulness of the data type on several examples, and highlight connections to related topics in category theory.},
booktitle = {Proceedings of the 13th ACM SIGPLAN International Symposium on Haskell},
pages = {54–66},
numpages = {13},
keywords = {Linear Algebra of Programming, Haskell, Probabilistic Programming, Data Analysis, Matrices, Quantum Programming},
location = {Virtual Event, USA},
series = {Haskell 2020}
}

@incollection{axi-stream,
  author = {ARM},
  title  = {AMBA®4 AXI4-Stream Protocol Specification},
  url    = {https://developer.arm.com/documentation/ihi0051/a/Introduction/About-the-AXI4-Stream-protocol},
  year = {2010},
  urldate = {2022-06-07}
}

@inproceedings{oldfhw,
author = {Zhai, Kuangya and Townsend, Richard and Lairmore, Lianne and Kim, Martha A. and Edwards, Stephen A.},
title = {Hardware Synthesis from a Recursive Functional Language},
year = {2015},
isbn = {9781467383219},
publisher = {IEEE Press},
abstract = {Abstraction in hardware description languages stalled at the register-transfer level decades ago, yet few alternatives have had much success, in part because they provide only modest gains in expressivity. We propose to make a much larger jump: a compiler that synthesizes hardware from behavioral functional specifications. Our compiler translates general Haskell programs into a restricted intermediate representation before applying a series of semantics-preserving transformations, concluding with a simple syntax-directed translation to SystemVerilog. Here, we present the overall framework for this compiler, focusing on the intermediate representations involved and our method for translating general recursive functions into equivalent hardware. We conclude with experimental results that depict the performance and resource usage of the circuitry generated with our compiler.},
booktitle = {Proceedings of the 10th International Conference on Hardware/Software Codesign and System Synthesis},
pages = {83–93},
numpages = {11},
keywords = {high-level synthesis, recursion, functional hardware},
location = {Amsterdam, The Netherlands},
series = {CODES '15}
}

@inproceedings{predict,
author = {Nigam, Rachit and Atapattu, Sachille and Thomas, Samuel and Li, Zhijing and Bauer, Theodore and Ye, Yuwei and Koti, Apurva and Sampson, Adrian and Zhang, Zhiru},
title = {Predictable Accelerator Design with Time-Sensitive Affine Types},
year = {2020},
isbn = {9781450376136},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385412.3385974},
doi = {10.1145/3385412.3385974},
abstract = {Field-programmable gate arrays (FPGAs) provide an opportunity to co-design applications with hardware accelerators, yet they remain difficult to program. High-level synthesis (HLS) tools promise to raise the level of abstraction by compiling C or C++ to accelerator designs. Repurposing legacy software languages, however, requires complex heuristics to map imperative code onto hardware structures. We find that the black-box heuristics in HLS can be unpredictable: changing parameters in the program that should improve performance can counterintuitively yield slower and larger designs. This paper proposes a type system that restricts HLS to programs that can predictably compile to hardware accelerators. The key idea is to model consumable hardware resources with a time-sensitive affine type system that prevents simultaneous uses of the same hardware structure. We implement the type system in Dahlia, a language that compiles to HLS C++, and show that it can reduce the size of HLS parameter spaces while accepting Pareto-optimal designs.},
booktitle = {Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {393–407},
numpages = {15},
keywords = {Affine Type Systems, High-Level Synthesis},
location = {London, UK},
series = {PLDI 2020}
}

@incollection{newsuitesparse,
  author = {Timothy A.\,Davis},
  title = {Algorithm 10xx: SuiteSparse:GraphBLAS: parallel graph algorithms in the language of
sparse linear algebra},
  url = {https://raw.githubusercontent.com/DrTimothyAldenDavis/GraphBLAS/stable/Doc/toms_parallel_grb2.pdf},
  year = {2022}, 
  urldate = {2022-06-07}
}

@article{superreduceron,
author = {Reich, Jason and Naylor, Matthew and Runciman, Colin},
year = {2010},
month = {12},
pages = {},
title = {Supercompilation and the Reduceron}
}

@article{affine,
author = {Acharya, Aravind and Bondhugula, Uday and Cohen, Albert},
title = {Effective Loop Fusion in Polyhedral Compilation Using Fusion Conflict Graphs},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3416510},
doi = {10.1145/3416510},
abstract = {Polyhedral auto-transformation frameworks are known to find efficient loop transformations that maximize locality and parallelism and minimize synchronization. While complex loop transformations are routinely modeled in these frameworks, they tend to rely on ad hoc heuristics for loop fusion. Although there exist multiple loop fusion models with cost functions to maximize locality and parallelism, these models involve separate optimization steps rather than seamlessly integrating with other loop transformations like loop permutation, scaling, and shifting. Incorporating parallelism-preserving loop fusion heuristics into existing affine transformation frameworks like Pluto, LLVM-Polly, PPCG, and PoCC requires solving a large number of Integer Linear Programming formulations, which increase auto-transformation times significantly.In this work, we incorporate polynomial time loop fusion heuristics into the Pluto-lp-dfp framework. We present a data structure called the fusion conflict graph (FCG), which enables us to efficiently model loop fusion in the presence of other affine loop transformations. We propose a clustering heuristic to group the vertices of the FCG, which further enables us to provide three different polynomial time greedy fusion heuristics, namely, maximal fusion, typed fusion, and hybrid fusion, while maintaining the compile time improvements of Pluto-lp-dfp over Pluto. Our experiments reveal that the hybrid fusion model, in conjunction with Pluto’s cost function, finds efficient transformations that outperform PoCC and Pluto by mean factors of 1.8\texttimes{} and 1.07\texttimes{}, respectively, with a maximum performance improvement of 14\texttimes{} over PoCC and 2.6\texttimes{} over Pluto.},
journal = {ACM Trans. Archit. Code Optim.},
month = {sep},
articleno = {26},
numpages = {26},
keywords = {fusion conflict graph, Affine transformations, pluto algorithm}
}